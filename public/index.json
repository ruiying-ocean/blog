[{"categories":["Science"],"content":"Introduction Functional diversity is a component of multifacet diversity concept. Differing from species perspective, it is based on functional trait, i.e., morphological, physiological, phenological, behavioral, or life history features that govern the functional role of organisms. ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:1:0","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"Quantification of functional space ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:2:0","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"CWM (community weighted mean) The index corresponds, for each trait (either quantitative or qualitative), to the average trait values in a community weighted by the species’ relative abundances. ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:2:1","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"Sum of branch length (Petchey and Gaston, 2006) species x traits -\u003e distance matrix -\u003e cluster/dendrogram -\u003e sum of the branch lengths; get species in each group ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:2:2","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"Trait space Use trait as dimension, plot each species in the functional space. The rest of calculation is same to the trait-distance based method. The trait based method has two limitations: (1) limited tratis can be used, usually visuliased as 2D; (2) trait can be co-varied, i.e., not linearly independent. These two can be solved using PCoA. ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:2:3","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"Trait Distance based Species (sample) x trait (variable) data frame to calculate species distance (or dissimilarity) matrix (i.e. how species is similar to each other). Then based on this dissimilarity matrix, use PCoA to decrease the dimension. The PCs will become the new coordinate system (similar to direct trait space but using linear combination of those trait), and each species will have a position (e.g., i,j,k) in this system. The essence of site (assemblage) x species data is to describe the composition of each assemblage. We can plot each species (coloured/groupped by assemblage, abundance/biomass as dot size) in the new coordinate system and then do some quantification. The abundance data basically determines the centre of gravity (or centroid) within each assemblage. The group can be temporal (before and after) or spatial (different sites). The following is a table of listed functional indices and important term. Functional indices Definition Reference Ecological meaning Centroid The biomass-weighted trait value Functional richness Area of the convex hull Villéger et al. 2008 Functional niche size, not need abundance data Functional dispersion biomass-weighted mean distance of individual species to the centroid of all species in the communit Laliberté and Legendre, 2010 Second moment: variance Functional evenness The regularity of biomass-density distribution along the minimum spanning tree (MST) Villéger et al. 2008 niche differentiation Functional divergence The biomass-weighted distance to mean circle (the average distance to the centroid) Villéger et al. 2008 Rao’s entropy index average/sum of the dissimilarity between each pair of species in a community, weighted by the abundances of both species Rao and FDis have inherently the same mathematical basis as variance Functional specialisation The species near the centroid is defined as generlised species and away the centroid as specialised with extreme traits. The abundance change therefore reflects the specialisation. Functional originality The abundance weighted mean distance to the nearest species from the global species pool. Lower FOri if species tend to gather together (i.e. lower distance). This is equivalent to higher functional redundancy (more species with similar functional traits/roles). MPD Mean weighted distance between all pairs of species. MNND Mean weighted nearest neighbor distance All these indices can be classfied into 3 primary component of functional diversity: (1) functional richness; (2) evenness; (3) divergence. divergence v.s. dispersion? 个人理解, 一个是一维 (比如函数的发散收敛), 一个是二维(物种空间分布的散度) ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:2:4","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"Functional entities (group or cluster) based (from Mouillot et al. 2014) Functional entity richness: the number of functional entities Functional redundancy: the average number of species in FE present in a given assemblage (higher species relative to functional entities gives higher redundancy) Functional over-redundancy: Because FRed cannot distinguish the two extreme case: low S/low N and high S/high N, the FOR indice is defined as the proportion of the excessive species that are in the redundant FEs (number of species \u003e average). Functional vulnerability: The proportion of FE with only 1 species in a given assemblage Following is the equation: with S the total number of species, N the total number of functional entities, and $n_i$ the number of species in functional entity i, $$ FRed = \\frac{S}{N};\\ FOR = \\frac{\\sum_{i=1}^{N}[max(n_i, FRed) - FRed]}{S};\\ FVul = \\frac{N - \\sum_{i=1}^{N}min(n_i - 1, 1)}{N}\\ $$ ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:2:5","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"Functional $\\beta$ diversity Functional beta-diversity indices are computed for a pair of assemblages based on the overlap between the convex hulls shaping their respective species. References Magneville, C., Loiseau, N., Albouy, C., Casajus, N., Claverie, T., Escalas, A., Leprieur, F., Maire, E., Mouillot, D. and Villéger, S. (2022), mFD: an R package to compute and illustrate the multiple facets of functional diversity. Ecography, 2022:. https://doi.org/10.1111/ecog.05904 Villéger, S., Mason, N.W.H. and Mouillot, D. (2008), New multidimensional functional diversity indices for a multifaceted framework in functional ecology. Ecology, 89: 2290-2301. https://doi.org/10.1890/07-1206.1 Mouillot, D., Villéger, S., Parravicini, V., Kulbicki, M., Arias-González, J. E., Bender, M., et al. (2014). Functional over-redundancy and high functional vulnerability in global fish faunas on tropical reefs. Proceedings of the National Academy of Sciences, 111(38), 13757–13762. https://doi.org/10/f6hw3n Mouillot, D., Graham, N. A. J., Villéger, S., Mason, N. W. H., \u0026 Bellwood, D. R. (2013). A functional approach reveals community responses to disturbances. Trends in Ecology \u0026 Evolution, 28(3), 167–177. https://doi.org/10.1016/j.tree.2012.10.004 Laliberté, E. and Legendre, P. (2010), A distance-based framework for measuring functional diversity from multiple traits. Ecology, 91: 299-305. https://doi.org/10.1890/08-2244.1 ","date":"2022-09-28","objectID":"/2022-09-28-overview-of-functional-diversity/:2:6","tags":null,"title":"Overview of functional diversity","uri":"/2022-09-28-overview-of-functional-diversity/"},{"categories":["Science"],"content":"Click here to download PDF ","date":"2022-02-21","objectID":"/2022-02-21-carbon-chemistry-and-biological-pump/:0:0","tags":["tag1","tag2"],"title":"Carbon chemistry and biological pump","uri":"/2022-02-21-carbon-chemistry-and-biological-pump/"},{"categories":["Programming"],"content":"Fortran Basics ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:0:0","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Data types and declaraion Character Real (same as double in C-series languages ) Integer Complex Logical (.TRUE. and .FALSE.) ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:1:0","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Arrays Whole-array arithmetic (similar to some functional programming) Column major order/indexing (inherited by R/Matlab, unlike C/Python), therefore, a(1,1), a(2,1), a(3,1) will be faster to index. ! ways to declare data ! Keyword `parameter` means immutable constant integer, parameter :: a = 1, b = 2 ! or integer, parameter :: a, b a = 1 b = 2 !character character(len=4) :: first character(5) :: last_name ! String concatenation full_name = first_name//' '//last_name ! ways to declare arrays real :: vec(10) real, dimension(10,2) :: vec !dynamic arrays, also called allocatable arrays integer, allocatable :: a(:) ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:1:1","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Derived types Derived types are “struct” in C/C++. A derived type is a special form of data type that can encapsulate other built-in types as well as other derived types !create a derived type type :: t_pair integer :: x real :: y end type ! use t_pair type(t_pair) :: pair pair%x = 1 pair%y = 0.1 ! or do this at once type(t_pair) :: pair pair = t_pair(x=1, y=0.1) ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:1:2","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Implicit and explicit declaration FORTRAN has a historical feature called implicit typing which allows variable types to be inferred by the compiler based on the first letter of the variable (stupid). Basically, any variable that began with I, J, K, L, M, or N was an integer, and it was a real (floating point) otherwise. Anyway, always use implict none to override this stupid declaring! ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:1:3","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Structure Program: Top-level unit that can be invoked only from the operating system. It contains sub-program as following. Function: An executable subprogram that is invoked from expressions and always returns a single result. No side effects.can only call it from the main program or another procedure. Subroutine: Modify multiple arguments in-place but can’t be used in expressions. Cause side effcts. (side effects can be prevented by pure statement) Module: A nonexecutable collection of variable, function, and subroutine definitions (since F90). The variable declaration and procedure definition sections (function and subroutine) are separated with a contains statement. Submodule: Extends an existing module and is used for defining variable and procedure definitions that only that module can access; useful for more complex apps and libraries In FORTRAN function/subroutine, dummy parameters are same as formal argument (形参) in other languages. In other languages, dummy arguments equals unused arguments. In subroutine, INTEND (IN): indicating take value from outside and cannot be modified INTEND (OUT): indicating that their values will be computed and passed to the outside. ! function always return a result total = sum(1, 2) ! subroutine modifies input parameters ! and must be called by *call* call add(a, 3) ! define module module mod_test end module mod_test ! like from xx import xx in Python use mod_test, only: xxx ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:2:0","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"IO ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:3:0","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Standard streams Standard streams include standard input/output/error. 标准输入stdin是指从键盘输入，标准输出stdout是指输出到终端， 如printf, system.out.println(). 标准错误stderr是另外一种输出流，用于输出错误消息或诊断. general I/O STATEMENTS READ(unit, format) item1, item2,... WRITE(unit, format) item1, item2,... ! In many cases we use * which tell the compiler to use any format it likes WRITE(*, *) item1, item2, ... READ(*, *) item1, item2,... File handler: a identifier assigned to an open file that is currently being utilized by an operating system An I/O unit is like a file handle in other programming languages. It’s a unique identifier that’s assigned to a file when you open it. The first asterisk * means the input comes from the keyboard in a READ statement and goes to the screen in a WRITE statement. The second asterisk (*) means the free format or list-directed: multiple variables in the sequence. program standard_streams ! =\u003e means alias use iso_fortran_env, only: stdin =\u003e input_unit, stdout =\u003e output_unit, stderr =\u003e error_unit implicit none character(len=1000) :: text read(stdin, '(a)') text ! trim() Remove trailing blank characters of a string write(stdout, '(a)') trim(text) write(stderr, '(a)') 'This is an error message' end program standard_streams ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:3:1","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Format string ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:3:2","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Python # format specifier Python # d -\u003e integer; f -\u003e float; s -\u003e string # use format or % %4.2f %4.2f means 4 characters at total, with 2 floating points. ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:3:3","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Fortran ! format specifier is a string like '(e3.4)', the first letter means different data types and is surrounded by () ! l -\u003e logic, i -\u003e integer, es -\u003e exponential (scientific, 1.2E+02), en (engineering, 12E+01), g (any, OS-independent) f4.3 -\u003e float type, 4 character, three decimals ! integer: ix.y, x -\u003e how many characters, y -\u003e must use y characters (so add zeros if necessary) i4.3 -\u003e 42 to ` 042` ! Leading number -\u003e apply the same format to multiple characters 2(f6.3) -\u003e will cause no white space between these 2 values ! therefore we need manually inserat `spaces`, here 2x means 2 whitespaces 2(f6.3, 2x) ![](images/iShot2022-02-18 18.33.21.png) Legacy: use ID to label and format statement (i.e. they are separated!) ![](images/iShot2022-02-18 18.33.49.png) ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:3:4","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"File IO open(unit, file=filename, action=“read/write/readwrite”, position='append/asis/rewind’), ! file unit is OS dependent and unknown ahead of time ! file unit is assigned only to one file before close. You can also determine the unit by yourself. ! 形参 `file =` can’t be omitted ! POSITION ! Rewinding -\u003e start at the beginning ! asis -\u003e begining if a fresh file, otherwise go to previous position ! append -\u003e final position writing file write(fileunit, format_string) , text flush(fileunit) !flush the write buffer to the file check existence of file logical :: file_existence inquire(file=trim(filename), exist=file_exists) Error handling keywords Each of the read, write, open, close, inquire, flush, and rewind statements allows passing the iostat and err keyword parameters: iostat = 0 if all good, otherwise positive err—An integer error label to which the program will jump if the error is encountered e.g. write(fileunit, ‘(a)’, iostat = a_number, err=b_number) ! if error, the program jumps to here to close the file b_number close(fileunit) TODO: parallel fortran compile and linking ","date":"2022-02-18","objectID":"/2022-02-18-fortran-basics/:3:5","tags":null,"title":"Fortran basics","uri":"/2022-02-18-fortran-basics/"},{"categories":["Programming"],"content":"Introduction This post is to simply introduce how to make a map in R environment, or more officially, geographic/spatial visualisation. However, I just found numerous methods to do this in R, depending on which data type you have. So this post will not introduce the basic of R and GIS. After all, I am also not an expert in this. To make a map, at least two types of data are needed: Geographic Information System (GIS) data for position Research data per se for value Sometimes these two are combined to a unified data (e.g., population data as an attribute in a shapefile). However, in most cases for those who are not studying geography (like me), we have to join the research data (in csv, netCDF) to GIS fields based on shared “key/id column”. The relevant GIS data probably can be found in third-party packages such as maps or mapdata, but for more demands like custom resolution, one have to download in other sources. CSV file with lat and long columns There are two methods to plot a csv data frame on a map: plot layers using ggplot2 transform to sf Because the latter one is same to sections below, so I will introduce ggplot2, which is very (but not limitedly) proficient at analysing data frames. library(ggplot2) library(maps) # outline data for continents,countries library(mapdata) # extra map datasets library(mapproj) # map projection #library(maptools) # a quickest method to plot a global map # map(\"world\") # Here I create a simple dataframe, which can be replaced to your data by read.csv() toy_df \u003c- data.frame(city = c(\"Bristol\", \"Shangrao\"), long = c(51.45, 28.45), lat = c(-2.59, 117.94)) world \u003c- map_data(\"world\") # a ggplot2 function to get a world data.frame,see also borders # notice x is lat and y is long, which differs normal impression ggplot(world) + geom_polygon(aes(x = long, y = lat, group=group)) + geom_label(data= toy_df, aes(lat, long, label=city)) + coord_map(\"mollweide\", xlim=c(-180,180)) + # change the projection theme_minimal() Actuallyggfortify provides the autoplot function, which is a quicker wrapper for ggplot2. So we can do the same by using less command. library(ggfortify) world \u003c- map('world', plot = FALSE, fill = TRUE) autoplot(world, geom = 'polygon') + geom_point(data = toy_df, aes(lat, long), color=\"red\", size=2) There is another geom type: geom_map in ggplot. The difference between geom_map and geom_polygon is that the latter just plot the polygon (or position) and does not care about the value, but the geom_map contains both position and value information. Therefore, there must be a id columns shared by both polygon and value data frames, but no need to add lat/long in aes(). An example fr_map \u003c- map_data(\"france\") fr_data \u003c- data.frame(region = unique(fr_map$region), value = rnorm(length(unique(fr_map$region)))) ggplot(fr_data, aes(map_id = region)) + geom_map(aes(fill = value), map=fr_map) + expand_limits(x = fr_map$long, y = fr_map$lat) + coord_fixed() sf object + geom_sf shp file can be read in R through sf or rgal, and then plot using ggplot . #from https://r-spatial.org/r/2018/10/25/ggplot2-sf.htm library(sf) ## Linking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE library(rnaturalearth) #another public map data package #library(rnaturalearthdata) it_data =st_as_sf(map(\"italy\", plot = FALSE, fill = TRUE)) #polygons it_sf \u003c- ne_countries(scale = \"medium\", country=\"italy\",returnclass = \"sf\") #an outline ggplot(it_sf)+geom_sf()+geom_sf(data = it_data, fill = NA) #and you can add more geom_sf() based on data in your hand #plot(uk_sf$geometry) #uk_sf$geometry equals st_geomety(uk_sf) sf object + tmap tmap has a similar layer-based syntax to plot map, but should be more professional and specilised than ggplot2. #from https://geocompr.robinlovelace.net/adv-map.html library(spData) #library(spDataLarge) library(tmap) library(sf) world \u003c- spData::world toy_sf \u003c- st_as_sf(toy_df, coords = c(\"lat\", \"long\"), crs=4326) #WGS84 tm_shape(world)+tm_borders()+tm_fill()+ tm_shape(toy_sf) + tm_dots","date":"2021-11-19","objectID":"/2021-11-19-cartography-in-r/:0:0","tags":["R; Data Science"],"title":"Cartography in R","uri":"/2021-11-19-cartography-in-r/"},{"categories":["Programming"],"content":"Study vim via vimtutor I’ve been curious about vim style of editing for a long time. There is a huge group of people using vim and this group is certainly larger than Emacs'. Even in Emacs community, there’s a significant proportion of users using evil keybinding. I naturally started to wonder how magic this editor can be and why people reckon it as the opposite of Emacs. So several days ago, I tried vimtutor, a simple tutor, and began to study more shortcuts than “jkhl” (I’ve already known this). Here’s my experience and thoughts! Different style of logics Vim uses text-object as a unit to operate, e.g., dw to delete (until) word. I found it very easy to understand and remember, while Emacs’s keybinding usually requires more times of pressing because of prefix keys (e.g., C-c). If someone doesn’t change the default keymap of keyboard, it will be very uncomfortable to press left Ctrl which locates at the very left-bottom corner. Even I have remap left Ctrl with Caps, it’s still prone to be fatigued after consecutive-hour typing. Efficiency But is vim more efficient than Emacs keybinding? I don’t literally think so. I believe when you are used to one of them, the efficiency should not be significantly different. For example, how much time you would save if you use “dd” instead of “C-k”, or “dw” instead of “C-d”? Maybe zero, or even negative :(. I have tried evil and I think it’s slowing down my productivity because I’ve already familiar with Vanilla Emacs. It won’t be worthwhile to switch it after another long time of studying. Philosophy Emacs users believe in “living in Emacs”, while vim users trust “do one thing, and do it better”. For example, Emacs can use terminal emulator (and use vim haha) or receive Email within it. It’s a difference of “all-in-one” and “division and cooperation”. To be honest, each one has its limitations and advantages. Emacs certainly has higher extensibility but is also more bloated. For instance, my Emacs is shipped with more than 100 packages and costs ca. 1s to start up. Even if this is already amazing, this is sadly a result of high optimization (lazy-load, replace time-costing packages, native compilation etc). In contrast, a “coarse” configuration may cost 7-8s or even more. Vim won’t have such a concern (according to my limited knowledge) but you can see that vim development is not as active as Emacs. Choose your tool I am keeping telling myself that tool is just tool. Although I love playing with Emacs, I also use Sublime Text (with license), Visual Studio Code, and some IDEs like Rstudio, PyCharm. They all are brilliant tools and have no conflicts with each other. Just choose yours according to the usage scenarios. For example, I always use Sublime Text as an alternative of the stupid Notepad on Windows. When I log in remote machines via ssh, I certainly use Emacs. Each one will be one of my toolbox without any issue! ","date":"2021-07-31","objectID":"/2021-07-31-experience-of-studying-vim/:0:0","tags":["Emacs; Vim"],"title":"Experience of studying vim","uri":"/2021-07-31-experience-of-studying-vim/"},{"categories":["Programming"],"content":"There’s no doubt that Rstudio is the No.1 IDE in R world. However, it’s intolerable that it doesn’t support a good dark theme. Although one can choose some colour schemes by default, you may still find the panel board is blue even if you have setted a “dark theme”. And to be honest, this has been a good reason for me to not use Rstudio: it is too ugly. Yesterday I found a good package – darkstudio to solve this. In addition to rscodeio, it now finally becomes sexy (The screenshot is done by iShot). ","date":"2021-07-16","objectID":"/2021-07-16-truly-dark-theme-of-rstudio/:0:0","tags":[],"title":"Truly dark theme of Rstudio","uri":"/2021-07-16-truly-dark-theme-of-rstudio/"},{"categories":["Programming"],"content":"The new Windows Terminal seems to make programming on Windows much better than ever. It is now beautiful, customizable as its counterparts. Today I just found it included a new GUI setting to make self-customization easier and more friendly. Download/Upgrade Find latest Windows Terminal and Powershell in their release pages (windows terminal, powershell) Customization The latest windows terminal includes a GUI setting interface (the original one is simply a json file), to open it just Ctrl + , and play with your own! It is also possible to do something as below to enable Emacs keybinding and set new theme # install posh-git and oh-my-posh Install-Module -Name posh-git -AllowPrerelease -Force Install-Module oh-my-posh -Scope CurrentUser -RequiredVersion 2.0.412 # install PSreadline to enable Emacs keybinding Install-Module -Name PSReadLine -Scope CurrentUser -Force -SkipPublisherCheck # edit profile file sublime_text.ext $PROFILE # then add Import-Module posh-git Import-Module oh-my-posh Set-Theme pure # if you use Emacs keybinding Set-PSReadLineOption -EditMode Emacs Couple with the other new post, Now I can operate remote file more smoothly. ","date":"2021-07-12","objectID":"/2021-07-12-try-windows-terminal-powershell/:0:0","tags":[],"title":"Try Windows Terminal + Powershell","uri":"/2021-07-12-try-windows-terminal-powershell/"},{"categories":["Programming"],"content":"My daily work includes edit files remotely via ssh. Thus I have some solutions to run Emacs on Windows and use tramp to make this possible without costing time learning a new editor. However, tramp would be relatively slow if I’m using scp protocol. So I decided to try to directly run Emacs on remote terminal. Install latest Emacs I can’t and won’t wish to install Emacs 26/27/28 via compiling in a CentOS machine without root permission. Thus my way is to use conda to run it. conda install Emacs -c conda-forge Enable mouse operation for terminal Emacs (unless (display-graphic-p) (xterm-mouse-mode 1) (global-set-key (kbd \"\u003cmouse-4\u003e\") 'scroll-down-line) (global-set-key (kbd \"\u003cmouse-5\u003e\") 'scroll-up-line) ) Use new Emacs without activating conda However, I’ve got a new task that if I add miniconda to the top of $PATH, my model which uses python2 won’t work properly. So I alias Emacs directly to ~/miniconda/bin/emacs-27.2 to avoid using default last-century (actually not) Emacs. And if I add a package conda.el to manage conda environment in shell: (use-package conda :config (setq conda-anaconda-home (expand-file-name \"~/miniconda3\")) (setq conda-env-home-directory (expand-file-name \"~/miniconda3\")) (conda-env-initialize-interactive-shells)) I just found I can simply put conda path before default Emacs but after python2. But the ad of my way is that I can use conda packages like pylsp without exporting its path in the shell profile. The last interesting thing I just update some conda packages and found Emacs broken because of some dependencies. After googling I surprisingly found conda can rollback, how amazing! conda list --revisions conda install --revision [revision number] ","date":"2021-07-12","objectID":"/2021-07-12-use-emacs-on-a-remote-shell/:0:0","tags":[],"title":"Use Emacs on a remote shell","uri":"/2021-07-12-use-emacs-on-a-remote-shell/"},{"categories":["Programming"],"content":"Features GCC Emacs uses libgccjit to compile and run Emacs Lisp as native code in form of re-loadable elf files. Therefore, it reaches a 3.8 times faster performance. More details can be found in the paper. Installation ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:0:0","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"MacOS First enable gcc with libgccjit. cd /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core/Formula and edit gcc.rb - languages = %w[c c++ objc obj-c++ fortran] + languages = %w[c c++ objc obj-c++ fortran jit] args = %W[ --prefix=#{prefix} --libdir=#{lib}/gcc/#{version_suffix} --disable-nls --enable-checking=release --enable-languages=#{languages.join(\",\")} --program-suffix=-#{version_suffix} --with-gmp=#{Formula[\"gmp\"].opt_prefix} --with-mpfr=#{Formula[\"mpfr\"].opt_prefix} --with-mpc=#{Formula[\"libmpc\"].opt_prefix} --with-isl=#{Formula[\"isl\"].opt_prefix} --with-zstd=#{Formula[\"zstd\"].opt_prefix} --with-pkgversion=#{pkgversion} --with-bugurl=#{tap.issues_url} + --enable-host-shared ] Then run brew install gcc. After successful installation of libgccjit, there are (at least) four ways to compile Emacs native comp (emacs-plus@28 works for my laptop with Big Sur 11.4). https://github.com/d12frosted/homebrew-emacs-plus.git https://github.com/daviderestivo/homebrew-emacs-head https://github.com/jimeh/build-emacs-for-macos.git https://github.com/jimeh/homebrew-emacs-builds.git (binary) After compilation, it takes a while to compile your lisp codes. Just wait. ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:1:0","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Windows ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:2:0","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Enable WSL2 and install ArchWSL To enable WSL2 in Windows, follow the steps in microsoft doc. You can also download kernel update package if you have already installed it. Since Arch Linux is not included in the Microsoft Store, we need to install it manually. However, yuk7 has a project to make this possible and easy to do based on a perfect documentation. #set root password passwd #setup sudoers echo \"%wheel ALL=(ALL) ALL\" \u003e /etc/sudoers.d/wheel #add user useradd -m -G wheel -s /bin/bash {username} #set user password passwd {username} #exit and use shell under windows to set default user .\\Arch.exe config --default-user {username} #login again to Arch sudo pacman-key --init sudo pacman-key --populate #update system pacman -Syu #install package as you want pacman -S \u003cpackage\u003e ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:2:1","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Install yay (an AUR helper) pacman -S --needed git base-devel git clone https://aur.archlinux.org/yay.git cd yay makepkg -si ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:2:2","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Add gpg key of libgccjit This step is needed because libgccjit key is not included in archwsl. Use the command below to add it. #replace \u003ckey\u003e with the hashed keys according to cmd notification gpg --keyserver keyserver.ubuntu.com --recv-key \u003ckey1\u003e \u003ckey2\u003e ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:2:3","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Install Emacs 28 (each one should work) yay -S emacs-gcc-wayland-devel-bin yay -S emacs-native-comp-git-enhanced yay -S emacs-native-comp-git #from source code git clone https://aur.archlinux.org/emacs-native-comp-git.git cd emacs-native-comp-git makepkg --syncdeps --install ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:2:4","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Use XServer to run GUI app After installation, you can run Emacs but it won’t show xwindow as you expect. You need use a XServer (e.g., MobaXterm, X410, VcXsrv) to do this. Several months ago I’ve written a post that describes my experience of using Emacs on Windows, check it if you like. It’s also worth noting that in the next generation of Windows, an official GUI support, WSLG, will be provided by Microsoft. You may want to check it. #add this line to your .zshrc/.bashrc export DISPLAY=$(cat /etc/resolv.conf | grep nameserver | awk '{print $2; exit;}'):0.0 #test if works, expected output: \u003cIP:port\u003e echo $DISPLAY #or nc -v \u003cIP\u003e 6000 #rescale GUI app export GDK_SCALE=2 #or export QT_SCALE_FACTOR=2 ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:2:5","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Linux (Ubuntu) If you don’t want to build from source or are not able to do this due to lack of full permission, you might need the following two ways. ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:3:0","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Emacs-ng Emacs-ng is based off of the branch of emacs, and regularly merges in the latest changes(this branch includes the native compilation feature from Andrea Corallo). One can easily download package file (.deb) from release page and use sudo dpkg -i xxx.deb to install it. Note Emacs-ng includes many experimental features powered by webrender and Google V8 engine, which means it’s a fork instead of a Vanilla Emacs. ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:3:1","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Snap Emacs-snap is another way to install latest Emacs in Ubuntu. It’s maintained by Alex Murray and now it includes native-comp. Emacs configurations ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:3:2","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Clone straight.el (optional) The original boostrap code of straight.el won’t work in WSL2, so we need clone the repository to the .emacs.d directory. See the Debugging section of doc. git clone https://github.com/raxod502/straight.el.git ~/.emacs.d/straight/repos/straight.el ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:4:0","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Programming"],"content":"Native comp support Download your configuration file with codes below to unleash its power. (when (and (fboundp 'native-comp-available-p) (native-comp-available-p)) (progn (setq native-comp-async-report-warnings-errors nil) (setq comp-deferred-compilation t) (add-to-list 'native-comp-eln-load-path (expand-file-name \"eln-cache/\" user-emacs-directory)) (setq package-native-compile t) )) Conclusion My experience is that it’s significantly faster on Mac, which is why I spend more time cloning this on Windows. However, on WSL2 I really can’t find the difference because the Emacs 28 without native comp feature on WSL2 is already very fast (init time \u003c 1.0s). Given the blurry problem of running GUI app based on XServer on a high DPI screen, consider twice before your decision. ","date":"2021-07-02","objectID":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/:5:0","tags":["Emacs; WSL"],"title":"Install and use Emacs 28 Native comp (gccemacs)","uri":"/2021-07-02-install-and-use-emacs-28-native-comp-gccemacs/"},{"categories":["Statistic"],"content":" Basics Conditional probability Conditional probability is the probability of an event given something already happened. It is a joint probability divdied by marginal probability. \\[ P(A|B) = \\frac{P(AB)}{P(B)} \\] The | means “given”. Bayesian theorem Clearly \\(P(A|B)\\) has some relationship with \\(P(B|A)\\), someone called Bayes expressed this and invented his immortal theorem: \\[ P(A|B) = \\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|!A)P(!A)} \\] Bayesian theorem infers two things: The relationship between \\(P(A|B)\\) and \\(P(B|A)\\): \\[P(B|A)P(A)=P(A|B)P(B)=P(AB)\\] Bayesian inference: If you are given something, you can find its reverse. Bayesian inference and science What is science? Science refers to a system of acquiring knowledge. The scientific method consists of induction and deduction (see the figure below). Bayesian inference We can slightly change the theorem in case there are more than two hypotheses: \\[ Pr(H_i|data) = \\frac{\\color{pink}{Pr(data|H_i)}\\color{steelblue}Pr(H_i)}{\\sum_{j=1}^n \\color{pink}{Pr(data|H_i)}\\color{steelblue}Pr(H_i)} \\] \\(\\color{pink}{Pr(data|H_i)}\\) refers to \\(\\color{pink}{likelihood}\\), \\(\\color{steelblue}Pr(H_i)\\) refers to \\(\\color{steelblue}{prior}\\) probability, \\(Pr(A|B)\\) refers to posterior probability. If the probability is discrete, we use Pr(); otherwise, we use P() to represent the PDF distribution (and use integration to replace sum). \\[ P(\\theta|data) = \\frac{\\color{pink}{P(data|\\theta)}\\color{steelblue}P(\\theta)}{\\int \\color{pink}{P(data|\\theta)}\\color{steelblue}P(\\theta)d\\theta} \\] The \\(\\theta\\) here refers to the single parameter in our PDF distribution. If there are two or more, simply change it. You might find the former one is regrading to hypothesis test, while the later one refer to parameter estimation. And due to its special feature, Bayesian inference always gives distribution. Thus the point estimation is not existing here and the interval estimation will be so easy to do. In conclusion, Bayesian inference does work like below: Initial belief + New Data = Updated belief This is why it is so important and relevant to science today. Do Bayesian analysis 1. Hypotheses Hypotheses can be discrete or continuous. For example, we may estimate the \\(\\mu\\) (mean) of a normal distribution and assume it spans from 1 to 5 (Let us assume the \\(\\sigma\\), the variance, is known here). 2. (Parameter’s) prior distribution The parameter that we want to estimate is a random variable thus has its own distribution (and parameters). The parameter of \\(\\theta\\)’s distribution is called hyperparameter. In another word, hyperparameter is the parameters of prior and posterior distribution. The prior distribution has its name because it is condcuted before our data collection. You may wonder if the selection of prior influences the result, sadly it does. Thus a useful (informative) prior should be better selected. Otherwise, a non-informative prior will be used, e.g., uniform distribution or normal distribution. Here we know nothing and choose uniform distribution. 3. Collect data A dataset might contain various dimensions. If they are independent, we can calculate likelihood by multiplication. Assume we have got one data point \\(x\\). 4. Likelihood Profile Likelihood is the conditional probability given data collected. It can be written in \\(\\mathcal{L}(x|\\theta)\\), if we have the data \\(x\\) already collected. Likelihood is different from probability because for the pdf distribution, the probability of one single point is always 0. Probability only refers to the integration area from \\(a\\) to \\(b\\), while likelihood is the \\(y\\) value. This step generates likelihood profile that describe the distribution of parameter. It is the weights (权重) of prior distribution and is the one updating our belief. 5. (Parameters’s) posterior distribution If we are estimating continuos distribution, then we have prior distribution likelihood profile (distribution) Then we multiply them and calculate a new distribution: th","date":"2021-05-12","objectID":"/2021-05-12-fundemental-bayesian-analysis/:0:0","tags":[],"title":"Fundemental Bayesian analysis","uri":"/2021-05-12-fundemental-bayesian-analysis/"},{"categories":["Programming"],"content":"Basic syntax Character Description ^ start $ end . any one character * \u003e1 character [] include [^] not include (e.g. [^A-C] is any one except for ABC) \\w word = [A-Za-z0-9] \\W inverse of \\w A useful command grep -rnw '/path/to/somewhere/' -e 'pattern' -r recursive -n line number -w word regexp Shortcut If you use Emacs, you can forget the command and use projectile. This is a project managing package which provides strong search ability with ag/rg (you can still choose grep though). Update In Linux, fuzzy finding fzf is another interesting program. ","date":"2021-05-12","objectID":"/2021-05-12-a-grep-note/:0:0","tags":[],"title":"REGEXP note","uri":"/2021-05-12-a-grep-note/"},{"categories":["Programming"],"content":" What’s secondary index? Secondary index is similar to key but differ in Only reorder specific columns instead of entire data.table, and record the order vector in attribute index There can be \u003e 1 secondary index for a data.table (though you can have multiple keys per row). I treat secondary index as fast and simple key for subsetting. Set secondary index setindex(flights, origin) #or setindexv() head(flights) ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 1 1 14 13 AA JFK LAX 359 2475 ## 2: 2014 1 1 -3 13 AA JFK LAX 363 2475 ## 3: 2014 1 1 2 9 AA JFK LAX 351 2475 ## 4: 2014 1 1 -8 -26 AA LGA PBI 157 1035 ## 5: 2014 1 1 2 1 AA JFK LAX 350 2475 ## 6: 2014 1 1 4 0 AA EWR LAX 339 2454 ## hour ## 1: 9 ## 2: 11 ## 3: 19 ## 4: 7 ## 5: 13 ## 6: 18 names(attributes(flights)) ## [1] \"names\" \"row.names\" \"class\" ## [4] \".internal.selfref\" \"index\" Get secondary index setindex(flights, origin, dest) indices(flights) ## [1] \"origin\" \"origin__dest\" Why secondary index? Case 1: reordering is expensive Using setkey() does two things: Computing order vector Reordering entire data.table But the second one can be consuming, so secondary index do the first thing only and store the output vector into index. Case 2: there is only 1 key for 1 data.table If we have set one key, and need to reset one, we have to re-computer and re-order entire data.table. But the secondary index allows more. Case 3: reuse index The index attribute avoid repeated computing if an index already exists. Simply add verbose=TRUE in data.table arguments. Application of secondary index Fast subset using on flights[\"JFK\", on=\"origin\"] #works for both key and secondary index ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 1 1 14 13 AA JFK LAX 359 2475 ## 2: 2014 1 1 -3 13 AA JFK LAX 363 2475 ## 3: 2014 1 1 2 9 AA JFK LAX 351 2475 ## 4: 2014 1 1 2 1 AA JFK LAX 350 2475 ## 5: 2014 1 1 -2 -18 AA JFK LAX 338 2475 ## --- ## 81479: 2014 10 31 -4 -21 UA JFK SFO 337 2586 ## 81480: 2014 10 31 -2 -37 UA JFK SFO 344 2586 ## 81481: 2014 10 31 0 -33 UA JFK LAX 320 2475 ## 81482: 2014 10 31 -6 -38 UA JFK SFO 343 2586 ## 81483: 2014 10 31 -6 -38 UA JFK LAX 323 2475 ## hour ## 1: 9 ## 2: 11 ## 3: 19 ## 4: 13 ## 5: 21 ## --- ## 81479: 17 ## 81480: 18 ## 81481: 17 ## 81482: 9 ## 81483: 11 Other features as normal cases flights[.(\"LGA\", \"TPA\"), .(arr_delay), on = c(\"origin\", \"dest\")] ## arr_delay ## 1: 1 ## 2: 14 ## 3: -17 ## 4: -4 ## 5: -12 ## --- ## 1848: 39 ## 1849: -24 ## 1850: -12 ## 1851: 21 ## 1852: -11 #find more in vignettes ","date":"2021-05-07","objectID":"/2021-05-07-learning-data-table-5/:0:0","tags":[],"title":"learning data.table (5)","uri":"/2021-05-07-learning-data-table-5/"},{"categories":["Science"],"content":"Taxonomy 界 Kingdom 门 Phylum 纲 Class 目 Order 科 Family 属 Genus 种 Species 五界系统（非唯一） 植物界、动物界、原核生物界、原生生物界、真菌生物界、 ","date":"2021-05-06","objectID":"/2021-05-06-chinese-english-name-of-marine-organisms/:0:0","tags":[],"title":"Re-study biology/geology term in CN/EN","uri":"/2021-05-06-chinese-english-name-of-marine-organisms/"},{"categories":["Science"],"content":"常见分类 Prokaryote 原核生物 (无核膜) Eukaryota 真核生物 (有核膜) Protista 原生生物(Kingdom)（隶属于真核生物，亦称作单细胞生物） Protozoan 原生动物 (informal term) Metazoans（后生动物，动物界除原生动物外的其他动物，即多细胞动物） Rhizopods 根足生物 ","date":"2021-05-06","objectID":"/2021-05-06-chinese-english-name-of-marine-organisms/:1:0","tags":[],"title":"Re-study biology/geology term in CN/EN","uri":"/2021-05-06-chinese-english-name-of-marine-organisms/"},{"categories":["Science"],"content":"Phytoplankton Dinoflagellate 甲藻 (门) Charophyte 轮藻 Chrysophyte 金藻 Chlorophyta 绿藻 Rhodophyta 红藻 （大多是多细胞，紫菜） Phaeophyceae 褐藻（多细胞） Coccolithophore 球石藻 haptophyte 定鞭藻 Zooxanthellae 虫黄藻(coral的一种常见共生藻类) Cyanobacteria（蓝藻，也成为蓝细菌，属于原核生物细菌界，革兰氏阴性菌） Prochlorococcus (原绿球藻属，蓝藻的一属) Synechococcus (聚球藻属，蓝藻的另一属) Zooplankton copepod 桡足类 Zoology TBD 节肢动物 腔肠动物 Cell biology zooxanthellae pseudopod rhizopod cytoplasm Fish TBD Geological time scale 地质学 Structure: Eon(宙)-Era(代)-Period(纪)-Epoch(世)-age(期) + -- Precambrian（隐生宙） | |-- Archean（太古宙，初始生物的时期） | |-- Proterozoic（元古宙，久远的原始生物的时期） | +-- Phanerozoic（显生宙，现代生物存在的时期） | + -- Paleozoic（古生代，古代生物） | | -- Cambrian（寒武纪） | | -- Ordovician（奥陶纪） | | -- Silurian（志留纪） | | -- Devonian（泥盘纪） | | -- Carboniferous（石炭纪） | | -- Permian（二叠纪） | + -- Mesozoic（中生代，爬行动物） | | -- Triassic | | -- Jurassic | | -- Cretaceous | + -- Cenozoic（新生代，哺乳动物） | + -- Paleogene | | -- Paleocene | | -- Ecocene | | -- Oligocene | + -- Neogene | | -- Miocene | | -- Pliocene | + -- Quanternary | -- Pleistocene | -- Holocene ","date":"2021-05-06","objectID":"/2021-05-06-chinese-english-name-of-marine-organisms/:2:0","tags":[],"title":"Re-study biology/geology term in CN/EN","uri":"/2021-05-06-chinese-english-name-of-marine-organisms/"},{"categories":["Programming"],"content":" melt and dcast Actually I don’t know the difference of these two functions between data.table and reshape2, but the use should be same. melt converts wide to long library(data.table) s1 \u003c- \"family_id age_mother dob_child1 dob_child2 dob_child3 1 30 1998-11-26 2000-01-29 NA 2 27 1996-06-22 NA NA 3 26 2002-07-11 2004-04-05 2007-09-02 4 32 2004-10-10 2009-08-27 2012-07-21 5 29 2000-12-05 2005-02-28 NA\" DT \u003c- fread(s1) DT ## family_id age_mother dob_child1 dob_child2 dob_child3 ## 1: 1 30 1998-11-26 2000-01-29 \u003cNA\u003e ## 2: 2 27 1996-06-22 \u003cNA\u003e \u003cNA\u003e ## 3: 3 26 2002-07-11 2004-04-05 2007-09-02 ## 4: 4 32 2004-10-10 2009-08-27 2012-07-21 ## 5: 5 29 2000-12-05 2005-02-28 \u003cNA\u003e str(DT) ## Classes 'data.table' and 'data.frame': 5 obs. of 5 variables: ## $ family_id : int 1 2 3 4 5 ## $ age_mother: int 30 27 26 32 29 ## $ dob_child1: IDate, format: \"1998-11-26\" \"1996-06-22\" ... ## $ dob_child2: IDate, format: \"2000-01-29\" NA ... ## $ dob_child3: IDate, format: NA NA ... ## - attr(*, \".internal.selfref\")=\u003cexternalptr\u003e DT.melt \u003c- melt(DT, id.vars = c(\"family_id\",\"age_mother\"), measure.vars = c(\"dob_child1\", \"dob_child2\", \"dob_child3\"), variable.name = \"child\", value.name = \"dob\") head(DT.melt) ## family_id age_mother child dob ## 1: 1 30 dob_child1 1998-11-26 ## 2: 2 27 dob_child1 1996-06-22 ## 3: 3 26 dob_child1 2002-07-11 ## 4: 4 32 dob_child1 2004-10-10 ## 5: 5 29 dob_child1 2000-12-05 ## 6: 1 30 dob_child2 2000-01-29 If neither id.var and measure.var are specified , the id will assign all non-integer, logical, numeric columns. By default, var and value name is simply var and value. dcast converts long to wide dcast use formula as below dcast(DT.melt, family_id + age_mother ~ child, value.var = \"dob\") #value.var is the variable to fill all cells ## family_id age_mother dob_child1 dob_child2 dob_child3 ## 1: 1 30 1998-11-26 2000-01-29 \u003cNA\u003e ## 2: 2 27 1996-06-22 \u003cNA\u003e \u003cNA\u003e ## 3: 3 26 2002-07-11 2004-04-05 2007-09-02 ## 4: 4 32 2004-10-10 2009-08-27 2012-07-21 ## 5: 5 29 2000-12-05 2005-02-28 \u003cNA\u003e Limitation in combine multiple columns s2 \u003c- \"family_id age_mother dob_child1 dob_child2 dob_child3 gender_child1 gender_child2 gender_child3 1 30 1998-11-26 2000-01-29 NA 1 2 NA 2 27 1996-06-22 NA NA 2 NA NA 3 26 2002-07-11 2004-04-05 2007-09-02 2 2 1 4 32 2004-10-10 2009-08-27 2012-07-21 1 1 1 5 29 2000-12-05 2005-02-28 NA 2 1 NA\" DT \u003c- fread(s2) DT ## family_id age_mother dob_child1 dob_child2 dob_child3 gender_child1 ## 1: 1 30 1998-11-26 2000-01-29 \u003cNA\u003e 1 ## 2: 2 27 1996-06-22 \u003cNA\u003e \u003cNA\u003e 2 ## 3: 3 26 2002-07-11 2004-04-05 2007-09-02 2 ## 4: 4 32 2004-10-10 2009-08-27 2012-07-21 1 ## 5: 5 29 2000-12-05 2005-02-28 \u003cNA\u003e 2 ## gender_child2 gender_child3 ## 1: 2 NA ## 2: NA NA ## 3: 2 1 ## 4: 1 1 ## 5: 1 NA An untidy way to implement this (not run) DT.m1 = melt(DT, id = c(\"family_id\", \"age_mother\")) DT.m1[, c(\"variable\", \"child\") := tstrsplit(variable, \"_\", fixed = TRUE)] #I don't even understand this weird function tstrsplit DT.c1 = dcast(DT.m1, family_id + age_mother + child ~ variable, value.var = \"value\") DT.c1 Enhanced ways Pass a list to measure.vars where each element of the list contains the column that should be combined together. colA = paste(\"dob_child\", 1:3, sep = \"\") colB = paste(\"gender_child\", 1:3, sep = \"\") DT.m2 = melt(DT, measure = list(colA, colB), value.name = c(\"dob\", \"gender\")) #notice the measure paramter instead of measure.var DT.m2 ## family_id age_mother variable dob gender ## 1: 1 30 1 1998-11-26 1 ## 2: 2 27 1 1996-06-22 2 ## 3: 3 26 1 2002-07-11 2 ## 4: 4 32 1 2004-10-10 1 ## 5: 5 29 1 2000-12-05 2 ## 6: 1 30 2 2000-01-29 2 ## 7: 2 27 2 \u003cNA\u003e NA ## 8: 3 26 2 2004-04-05 2 ## 9: 4 32 2 2009-08-27 1 ## 10: 5 29 2 2005-02-28 1 ## 11: 1 30 3 \u003cNA\u003e NA ## 12: 2 27 3 \u003cNA\u003e NA ## 13: 3 26 3 2007-09-02 1 ## 14: 4 32 3 2012-07-21 1 ## 15: 5 29 3 \u003cNA\u003e NA The additional variable column is good to do dcast later and can be removed if necessary! Using patterns() DT.m2 = melt(DT, measure = patterns(\"^dob\", \"^gender\"), value.name = c(\"dob\", ","date":"2021-04-30","objectID":"/2021-04-30-learning-data-table-4/:0:0","tags":[],"title":"Learning data.table (4)","uri":"/2021-04-30-learning-data-table-4/"},{"categories":["Programming"],"content":" What’s key Key is very similar to the group_by concept, or the telephone number book in our world: when you want to find someone’s phone number, you go find his/her first name, then second name. The names here are key. Or as the data.table vignette shows, the key in data.table is inherited from rowname in data.frame. However, key is advantageous in each row can have many keys in dt, but only one rowname in df keys are not unique (you can have duplicate variable in key column) keys can be in various variable types key columns are well sorted How to set key setkey() or setkeyv(): the former one is better in interactive use, whilst the latter one is more of function-use. setkey(flights, origin, dest) #is equal to setkeyv(flights, c(\"origin\", \"dest\")) Feature of using key it modify data.table and return result invisibly it’s manipulating by reference as := operator and all set* family function (setkey, setname etc.) Do some work setkey(flights, origin, dest) # select j flights[.(\"LGA\", \"TPA\"), .(arr_delay)] # do sth in j flights[.(\"LGA\", \"TPA\"), max(arr_delay)] # use by flights[\"JFK\", max(dep_delay), keyby = month] mult and nomatch argument Very simply, mult choose how many matching rows to return, and nomatch selects if the unmatching NA should be returned or skipped. The default value of these two are “all” and “NA”. Setting nomatch=NULL kips queries with no matches. Ad of using key Key is based on binary search (二分法) with O(Log(N)) complexity, while the traditional vector scan method is simply scaning as the name shows. The complexity is O(N). But the document says the vector scan has been optimized in recent version thus is also binary search-based, otherwise you set the key to NULL and then it’s back to the slow one. ","date":"2021-04-29","objectID":"/2021-04-29-learning-data-table-3/:0:0","tags":[],"title":"Learning data.table (3)","uri":"/2021-04-29-learning-data-table-3/"},{"categories":["Programming"],"content":" #download data as usual library(data.table) library(magrittr) file_url \u003c- 'https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv' df \u003c- fread(file_url) Introduction This post studies the use of := operator which add/update/delete columns. The difference between := and default data.frame operation is the former does by reference and therefore is not deep copy and not assign any value to a variable. This causes faster speed, less memory use but some side effects. Two forms of := ways # LHS := RHS DT[, c(\"colA\", \"colB\") := list(valA, valB)] # function form DT[, `:=`(colA = valA, # valA is assigned to colA colB = valB)] Add/update/delete columns df[, `:=`(speed = distance / (air_time/60), delay = arr_delay + dep_delay)] %\u003e% head() ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 1 1 14 13 AA JFK LAX 359 2475 ## 2: 2014 1 1 -3 13 AA JFK LAX 363 2475 ## 3: 2014 1 1 2 9 AA JFK LAX 351 2475 ## 4: 2014 1 1 -8 -26 AA LGA PBI 157 1035 ## 5: 2014 1 1 2 1 AA JFK LAX 350 2475 ## 6: 2014 1 1 4 0 AA EWR LAX 339 2454 ## hour speed delay ## 1: 9 413.6490 27 ## 2: 11 409.0909 10 ## 3: 19 423.0769 11 ## 4: 7 395.5414 -34 ## 5: 13 424.2857 3 ## 6: 18 434.3363 4 Subassign - conditional update df[hour == 24L, hour := 0L][] #replace all hour 24 to 0 ## year month day dep_delay arr_delay carrier origin dest air_time ## 1: 2014 1 1 14 13 AA JFK LAX 359 ## 2: 2014 1 1 -3 13 AA JFK LAX 363 ## 3: 2014 1 1 2 9 AA JFK LAX 351 ## 4: 2014 1 1 -8 -26 AA LGA PBI 157 ## 5: 2014 1 1 2 1 AA JFK LAX 350 ## --- ## 253312: 2014 10 31 1 -30 UA LGA IAH 201 ## 253313: 2014 10 31 -5 -14 UA EWR IAH 189 ## 253314: 2014 10 31 -8 16 MQ LGA RDU 83 ## 253315: 2014 10 31 -4 15 MQ LGA DTW 75 ## 253316: 2014 10 31 -5 1 MQ LGA SDF 110 ## distance hour speed delay ## 1: 2475 9 413.6490 27 ## 2: 2475 11 409.0909 10 ## 3: 2475 19 423.0769 11 ## 4: 1035 7 395.5414 -34 ## 5: 2475 13 424.2857 3 ## --- ## 253312: 1416 14 422.6866 -29 ## 253313: 1400 8 444.4444 -19 ## 253314: 431 11 311.5663 8 ## 253315: 502 11 401.6000 11 ## 253316: 659 8 359.4545 -4 # note := returns the result invisibly, so we have extra [] here Delete columns df[, c(\"delay\") := NULL] Using by df[, max_speed := max(speed), by = .(origin, dest)] Multiple columns in_cols = c(\"dep_delay\", \"arr_delay\") out_cols = c(\"max_dep_delay\", \"max_arr_delay\") df[, c(out_cols) := lapply(.SD, max), by = month, .SD = in_cols][] %\u003e% head() ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 1 1 14 13 AA JFK LAX 359 2475 ## 2: 2014 1 1 -3 13 AA JFK LAX 363 2475 ## 3: 2014 1 1 2 9 AA JFK LAX 351 2475 ## 4: 2014 1 1 -8 -26 AA LGA PBI 157 1035 ## 5: 2014 1 1 2 1 AA JFK LAX 350 2475 ## 6: 2014 1 1 4 0 AA EWR LAX 339 2454 ## hour speed max_speed max_dep_delay max_arr_delay ## 1: 9 413.6490 526.5957 973 996 ## 2: 11 409.0909 526.5957 973 996 ## 3: 19 423.0769 526.5957 973 996 ## 4: 7 395.5414 517.5000 973 996 ## 5: 13 424.2857 526.5957 973 996 ## 6: 18 434.3363 518.4507 973 996 #note the c() in out_cols because we can not do out_cols := lapply(.SD, max). That would result in adding one new column named out_col. Side effects of := Because := refer to the memory directly, it can be dangerous in writing function: any operation would change the origin data set. Thus a better way is use copy() first and do other things in the duplicate one. ","date":"2021-04-25","objectID":"/2021-04-25-learning-data-table-2/:0:0","tags":[],"title":"Learning data.table (2)","uri":"/2021-04-25-learning-data-table-2/"},{"categories":["Programming"],"content":" Prepare data library(data.table) file_url \u003c- 'https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv' df \u003c- fread(file_url) head(df,3) ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 1 1 14 13 AA JFK LAX 359 2475 ## 2: 2014 1 1 -3 13 AA JFK LAX 363 2475 ## 3: 2014 1 1 2 9 AA JFK LAX 351 2475 ## hour ## 1: 9 ## 2: 11 ## 3: 19 Simple syntax data.table use one-line syntax like df[i, j, by] where i is the rows to select and to manipulate, j is the columns to select and how to manupulate it (e.g., mutate function in dplyr), by is the group option. Subset rows library(magrittr) #using condition sub_df \u003c- df[year==2014 \u0026 hour \u003c 10,] head(sub_df) ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 1 1 14 13 AA JFK LAX 359 2475 ## 2: 2014 1 1 -8 -26 AA LGA PBI 157 1035 ## 3: 2014 1 1 -7 -6 AA LGA ORD 142 733 ## 4: 2014 1 1 -7 0 AA LGA ORD 143 733 ## 5: 2014 1 1 -8 -17 AA LGA ORD 139 733 ## 6: 2014 1 1 -2 15 AA LGA ORD 145 733 ## hour ## 1: 9 ## 2: 7 ## 3: 5 ## 4: 6 ## 5: 6 ## 6: 7 #using index (not recommended because of bad readability and maintainance) sub_df \u003c- df[1:5,] head(sub_df) ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 1 1 14 13 AA JFK LAX 359 2475 ## 2: 2014 1 1 -3 13 AA JFK LAX 363 2475 ## 3: 2014 1 1 2 9 AA JFK LAX 351 2475 ## 4: 2014 1 1 -8 -26 AA LGA PBI 157 1035 ## 5: 2014 1 1 2 1 AA JFK LAX 350 2475 ## hour ## 1: 9 ## 2: 11 ## 3: 19 ## 4: 7 ## 5: 13 #i parameter can sort specific columns df[order(hour,-distance)] %\u003e% head() #`-` means descend order ## year month day dep_delay arr_delay carrier origin dest air_time distance ## 1: 2014 2 13 922 975 HA JFK HNL 659 4983 ## 2: 2014 7 3 254 221 AA JFK SFO 341 2586 ## 3: 2014 7 14 230 246 B6 JFK SFO 335 2586 ## 4: 2014 7 15 318 305 VX JFK SFO 343 2586 ## 5: 2014 1 4 244 201 UA EWR SFO 352 2565 ## 6: 2014 2 3 244 267 UA EWR SFO 395 2565 ## hour ## 1: 0 ## 2: 0 ## 3: 0 ## 4: 0 ## 5: 0 ## 6: 0 Subset columns #using list df[, .(dep_delay, arr_delay)] ## dep_delay arr_delay ## 1: 14 13 ## 2: -3 13 ## 3: 2 9 ## 4: -8 -26 ## 5: 2 1 ## --- ## 253312: 1 -30 ## 253313: -5 -14 ## 253314: -8 16 ## 253315: -4 15 ## 253316: -5 1 #which is same as df[, list(dep_delay, arr_delay)] ## dep_delay arr_delay ## 1: 14 13 ## 2: -3 13 ## 3: 2 9 ## 4: -8 -26 ## 5: 2 1 ## --- ## 253312: 1 -30 ## 253313: -5 -14 ## 253314: -8 16 ## 253315: -4 15 ## 253316: -5 1 # or df[, c(\"dep_delay\", \"arr_delay\")] ## dep_delay arr_delay ## 1: 14 13 ## 2: -3 13 ## 3: 2 9 ## 4: -8 -26 ## 5: 2 1 ## --- ## 253312: 1 -30 ## 253313: -5 -14 ## 253314: -8 16 ## 253315: -4 15 ## 253316: -5 1 # or list \u003c- c(\"dep_delay\", \"arr_delay\") df[, ..list] #use .. here from the convention of unix directory operation ## dep_delay arr_delay ## 1: 14 13 ## 2: -3 13 ## 3: 2 9 ## 4: -8 -26 ## 5: 2 1 ## --- ## 253312: 1 -30 ## 253313: -5 -14 ## 253314: -8 16 ## 253315: -4 15 ## 253316: -5 1 #but I understand in a better way: . means list, .. means defining and call this (two steps) # parameter *with* df[, list, with=FALSE] ## dep_delay arr_delay ## 1: 14 13 ## 2: -3 13 ## 3: 2 9 ## 4: -8 -26 ## 5: 2 1 ## --- ## 253312: 1 -30 ## 253313: -5 -14 ## 253314: -8 16 ## 253315: -4 15 ## 253316: -5 1 #with() is a functional programming style so we can treat columns as variable. with=FALSE means restoring to data.frame manipulation. with=TRUE is default #if there's only 1 col, the .() can be omitted df[, arr_delay] %\u003e% head() #a vector as the column itself ## [1] 13 13 9 -26 1 0 #we can also use index here df[, year:day] #var1 to var2 ## year month day ## 1: 2014 1 1 ## 2: 2014 1 1 ## 3: 2014 1 1 ## 4: 2014 1 1 ## 5: 2014 1 1 ## --- ## 253312: 2014 10 31 ## 253313: 2014 10 31 ## 253314: 2014 10 31 ## 253315: 2014 10 31 ## 253316: 2014 10 31 #deselect using - or ! df[, !c(\"arr_delay\", \"dep_delay\")] ## year month day carrier origin dest air_time distance hour ## 1: 2014 1 1 AA JFK LAX 359 2475 9 ## 2: 2014 1 ","date":"2021-04-23","objectID":"/2021-04-23-learning-data-table/:0:0","tags":[],"title":"Learning data.table (1)","uri":"/2021-04-23-learning-data-table/"},{"categories":["Life"],"content":"NPZ模型是一个经典的海洋生态系统(食物链)模型，NPZ三个字母分别代表Nutrients, Phytoplankton和Zooplankton。 浮游植物摄取海水中的C/N/P/Fe元素进行光合作用固碳, 而浮游动物graze浮游植物获取营养。最近扫地的时候，我发现人类社会亦是如此：劳动者利用工具，消耗自然资源生产商品，而资本家在商品交易过程中获得绝大数利益–同样也构成了食物链模型。不过反过来，由于大多人同时作为劳动者的同时也身为消费者，消费者的决定与信心直接决定了资本的走向与资本家的存亡，所以更合适的模型是劳动者-资本家-消费者，形成一个循环。 更有趣的是其中各个层级的动态。浮游植物（劳动者）相互竞争营养，但是最终受益的是浮游动物（资本家），此之谓\"内卷\"。资本家之间相互竞争，如AMD和INTEL的关系，受益的则是下游的消费者。实际上这种竞争也有利于生产/劳动人民。因为两家科技公司（或任意其他持有大量资本的企业、国家）相互竞争，一定程度上也提供了更多就业岗位。比如苏联与美国的军备竞赛，其实提供了许多资金给航天领域的科研从业人员（也是被压榨的一端）。 最近看到一篇论文（Finke and Denno, 2005. Ecology Letters）讲捕食者之间相互竞争一定程度上缓和了对生产者的压力，增加了整体的生物多样性。其实对人类又何尝不是呢？ 内卷是有利于资本家的，而\"卷资本家\"是利于劳动者和消费者的。 注: 本文的简单想法充满漏洞， 比如说资本家与劳动者的关系不是简单的“捕食”关系， 实际上劳动者所竞争的岗位直接与资本家相关，但是自然界当然并非如此， 营养水平与捕食者是不直接挂钩的。 总之， 经济学模型与生态学模型有相似之处，但绝对有许多差异。 ","date":"2021-04-21","objectID":"/2021-04-21-the-similarity-between-marine-ecosystem-and-human-society/:0:0","tags":[],"title":"NPZ模型与人类社会的共通之处","uri":"/2021-04-21-the-similarity-between-marine-ecosystem-and-human-society/"},{"categories":["Life"],"content":"Introduction Each researcher facing the pandemic would more or less shows the symptom of mentally sub-health. I feel so exceptionally strongly. As an introverted unsociable person who is even not good at English, I live in a studio and have nobody to talk with. Gradually I found myself unable to controlling my thoughts and showing significant OCD case. For more than two weeks, I do nothing but forcing myself to think of something and simultaneously forcing myself not to do so. More depressing is that I know this is wrong but I do not know what to do. After a long time of struggling, I get through this situation with much help from my friends, supervisors and family. The good side of this “wasted” time is somehow I can recognize my emotions and started to learn how to observe and control it. Therefore I decided to write what I have searched and concluded. Hope I can express myself clearly so that anyone reading this post can learn something when he/she need help to escape from the mental trap. Feelings in our brain I divided my thoughts into two parts: emotion and cognition. I don’t know if this division is scientifically correct, but I can confirm that these two are widely accepted concepts in Psychology after simply searching some keywords in Google Scholar (e.g. Okon-Singer et al., 2015). They interact with each other and collectively determine our motivation. Emotion is nature and subjective, covering 27 varieties such as admiration, anger, fear, joy, sexual desire (Cowen and Keltner, 2017). It is a neurophysiological response to some stimulus. For example, it is common for everyone to trigger sexual desire when a lovely body is observed. Therefore it is natural because all human have this “built-in” function. However, this is also subjective because people can have different kinds and extent of emotion when they face a similar thing. The past experience and cognition should decide how the certain emotion would appear. Cognition is learned and acquired. Thus it is not as natural and fast-responding and fading as emotion. In physiology, it is believed that the neocortex which plays an influential role in sleep, memory and learning processes is evolved later than the limbic system deciding the emotion and motivation (Wikipedia). This might be why we usually face the case that we cannot control our emotion even though we should not care it. Relax, strengthen cognition through meditation Because cognition is acquired, there are some ways to exercise it, e.g., meditation. Lutz et al., (2008) reviewed the possible mechanisms and functions of two varibles of meditation, focused attention (FA) meditation and open monitoring (OM) meditation. The former entails the voluntary focusing of attention on a chosen object, while the other involves nonreactive monitoring of the content of experience from moment to moment. For me, the later one is applicable and useful. Unfortunately I cannot give much details of how to practice this and this is not the purpose of this post. I would rather show how enhanced cognition can change our emotion and life in the following framework. As the Fig. 1a shows, five process link the stimulus, emotion/cognition and our final behavior/speech. Arrow a represents the native stress response, typical example is our desires. Arrow b represents the emotion-motivated behavior and speech like ingesting, sexual behavior, impolite speech to your loved ones and lots of other impulsive behaviors (which often causes our regret). Arrow c is the first function of cognition: regulating how emotions generated in certain contexts. Similarly, arrow d means treating our emotion purposely. A good example is the OM meditation which monitors emotion and let it pass naturally. Process c and d can be done simultaneously, in the thinking process like saying “you didn’t intend to do this, don’t be upset (d), you can do it better next time (c)”. The last process e is simple “two dots one line” pattern which occurs hundreds of times per","date":"2021-04-18","objectID":"/2021-04-18-an-ameteur-framework-of-my-feeling-and-thoughts/:0:0","tags":["Psychology","Cognition","Emotion"],"title":"An ameteur framework of feeling and thoughts in our brain","uri":"/2021-04-18-an-ameteur-framework-of-my-feeling-and-thoughts/"},{"categories":["Programming"],"content":" Use tibble to replace “old” data.frame Differences: print() by specifying rows; subset (you can do slice like in Pandas). library(tidyverse) library(magrittr) #mtcars %\u003e% print(n=10,width = Inf) #always print all columns, regardless of the width of the screen. mtcars[[1]] == mtcars[['mpg']] #first column/variable ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [31] TRUE TRUE mtcars[,1] == mtcars$mpg #the same ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [31] TRUE TRUE mtcars %\u003e% select(mpg) %\u003e% head(5) #select() is also used in subset but a little different ## mpg ## Mazda RX4 21.0 ## Mazda RX4 Wag 21.0 ## Datsun 710 22.8 ## Hornet 4 Drive 21.4 ## Hornet Sportabout 18.7 convert with data.frame df \u003c- tibble(foo = 1, bar = 'bar') class(as.data.frame(df)) #[1] \"data.frame\" ## [1] \"data.frame\" class(as_tibble(df)) #[1] \"tbl_df\" \"tbl\" \"data.frame\" ## [1] \"tbl_df\" \"tbl\" \"data.frame\" Reshape data What is Tidy data Column -\u003e variable, row -\u003e observation. Ad: 1. uniformity; 2. Placing variable in columns (or a “vector” in R) allows R and tidyverse to work naturally. e.g. mutate(mtcars,new_col = cyl+1) %\u003e% head(5) ## mpg cyl disp hp drat wt qsec vs am gear carb new_col ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 7 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 7 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 5 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 7 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 9 dplyr basics Pick observations by their values: filter() Reorder the rows: arrange() Pick variables by their names: select() Create new variable by computing based on existing variables: mutate() A simple summary: summarise() Group data by one or more variables: group_by() (always ungroup() after grouping) Pivot Longer table Question: Column names are not names of variables, but values of a variable. For example: head(table4a) ## # A tibble: 3 × 3 ## country `1999` `2000` ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 We can divide the two untidy columns into a variable column (with col_name ‘year’) and a value column (with col_name ‘cases’) table4a %\u003e% pivot_longer(c('1999','2000'), names_to = \"year\", values_to = \"cases\") ## # A tibble: 6 × 3 ## country year cases ## \u003cchr\u003e \u003cchr\u003e \u003cint\u003e ## 1 Afghanistan 1999 745 ## 2 Afghanistan 2000 2666 ## 3 Brazil 1999 37737 ## 4 Brazil 2000 80488 ## 5 China 1999 212258 ## 6 China 2000 213766 table4a %\u003e% gather(`1999`,`2000`,key = 'year',value = 'cases') #the gather() in tidyr is equal ## # A tibble: 6 × 3 ## country year cases ## \u003cchr\u003e \u003cchr\u003e \u003cint\u003e ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 Wider pivot Question: Observations is scattered across multiple rows e.g. the cases and population are both observation, which should be put in one row. head(table2,5) ## # A tibble: 5 × 4 ## country year type count ## \u003cchr\u003e \u003cint\u003e \u003cchr\u003e \u003cint\u003e ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 table2 %\u003e% pivot_wider(names_from = type, values_from = count) # here's 2 paramters only ## # A tibble: 6 × 4 ## country year cases population ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 table2 %\u003e% spread(type,count) #spread() is equal as well ## # A tibble: 6 × 4 ## country year cases population ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 ","date":"2021-01-06","objectID":"/2021-01-06-review-data-analysis-in-r/:0:0","tags":["R; Data Science"],"title":"Review data analysis in R","uri":"/2021-01-06-review-data-analysis-in-r/"},{"categories":["Programming"],"content":"What’s public key and private key (in my understanding) Public key and private key are generated pairwisely. Only each other can decode the other. One of the pair can be the lock and the other can be the key. SSH connection process Client sends a request Server receives the request and send pub_key to client client uses the pub_key to encrypt password and send back Server decodes it using private_key Core: use server’s public key to encrypt user’s password. SSH connection without typing passwords Client generate public and private key of itself, and store the public one in server local Server send a random string to client Client uses its private key to encrypt the random string Server try to use public key to decode Core: compare client’s public and private key without typing passwords It’s equal to ssh user@host 'mkdir -p .ssh \u0026\u0026 cat \u003e\u003e .ssh/authorized_keys' \u003c ~/.ssh/id_rsa.pub Then I went to search the linux commands… ","date":"2021-01-04","objectID":"/2021-01-04-ssh-and-some-linux-commands/:0:0","tags":["Linux","SSH"],"title":"SSH and Some Linux Commands","uri":"/2021-01-04-ssh-and-some-linux-commands/"},{"categories":["Programming"],"content":"How to generate ssh key on client PC and store in server ssh-keygen; ssh-copy-id user@host New-learned Linux commands Command Description \u003e redirect output (rewriting) » redirect output (append) \u003c redirect input to command \u0026\u0026 logic “AND”, or “if success then:” || logic “OR” ; like the “;” in C or Java sort ranking something Redirect example command 2\u003e\u00261 #is equal to \u0026\u003e What’s the number represents? 0 -\u003e stdin 1 -\u003e stdout 2 -\u003e stderr Because 1 is the default, so 1\u003e is equivalent to \u003e. The 2\u003e\u00261 means add stderr to stdout Example from stackoverflow echo test 1\u003e afile.txt #redirect stdout echo test 2\u003e afile.txt #redirect stderr (which is the bad result: warnings) echo test 1\u003e\u00262 afile.txt #redirect both What about both \u003c and \u003e appear? We usually have input first, output second, so command receive \u003c then \u003e output. e.g. cat \u003e output.txt \u003c input.txt ","date":"2021-01-04","objectID":"/2021-01-04-ssh-and-some-linux-commands/:1:0","tags":["Linux","SSH"],"title":"SSH and Some Linux Commands","uri":"/2021-01-04-ssh-and-some-linux-commands/"},{"categories":["Statistic"],"content":"Recently I studied PCA from MIT course. However, markdown doesn’t support equations so well as LaTeX, so I compiled a PDF file and embed the PDF file here. Check it. ","date":"2020-12-25","objectID":"/2020-12-25-principal-component-analysis/:0:0","tags":["PCA; Statistic; Linear algebra"],"title":"Principal Component Analysis","uri":"/2020-12-25-principal-component-analysis/"},{"categories":["Science"],"content":"Table of Contents Basic Install and Test Running model Model output Ocean circulation Tracing ocean circulation Results to view Climate of Past Cretaceous (70 Ma) early Eocene (56 Ma) Fossil fuel CO2 customise emission forcing scale Historical emission forcing Ocean biogeomchemical cycle nutrient’s control on biological productivity Iron and Phosphate fertilisation What to view EcoGEnIE Customization Result to view Basic ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:0:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Install and Test Use git to download source codes. make sure dependencies(gfortran, netCDF) are pre-installed. Modify user.mak to specify NetCDF path; and uncomment something in makefile.arc according to your system to use (see the instruction). Test the model by typing make testbiogem. ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:1:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Running model Command to run model: qsub -q dog.q -j y -o cgenie_log -V -S /bin/bash runmuffin.sh basic-cofing user-config years spin-file. Or another direct but not practical way: cd genie-main, and ./runmuffin.sh ... Parameters in qsub: -q: bind job to queue -j: y/n to merge stdout and stderr of job -o: output file -V: export all environment variables -S: shell to use To check, use qstat -f. Note.1: you CANNOT submit job with new base-config file directly. The correct way is to run the model at the command line to re-compile the model. Note2 : You should create a new config file and set control group in every new experiment. Do not attempt to modify configuration file directly. ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:2:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Model output Model output store in ~/cgenie_output. Two types of output are defined. Time-slices: *.nc(netcdf) files. (average) spatial distribution of properties (keytracer, flux, and physical characteristics) every Time-series: *.res files. Time-varying suitable reduced indicators Ocean circulation ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:3:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Tracing ocean circulation Basic-config to use: cgenie.eb_go_gs_ac_bg.worjh2.rb (contains red color tracer) What and where to inject your tracer: Variables: bg_par_forcing_name=\"pyyyyz_Fred\" #forcing name bg_par_force_point_i=22 #3D coordinate bg_par_force_point_j=33 bg_par_force_point_k=8 bg_par_ocn_force_scale_val_48=0.0 #scale in mol/yr ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:4:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Results to view ocn_colr in 3D netCDF Tracer distribution: ocn_int_colr (long name: water-column integrated tracer inventory) Atlantic streamfunction: phys_opsia Barotropic streamfunction: phys_psi (something like circulation in lat-lon plot.) Deep water formation: convective cost or ventilation age Trace inventory: biogem_series_ocn_colr.res What’s streamfunction? This link worth viewing. Basically, positive values represent clockwise direction along contour lines. Climate of Past Not many things to play with ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:5:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Cretaceous (70 Ma) Basic-config: cgenie.eb_go_gs_ac_bg.p0067f.NONE Add Color-injection: cgenie.eb_go_gs_ac_bg.p0067f.rb ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:6:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"early Eocene (56 Ma) Basic-config cgenie.eb_go_gs_ac_bg.p0055c.NONE Fossil fuel CO2 Basic-config: cgenie.eb_go_gs_ac_bg.worjh2.BASE ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:7:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"customise emission forcing scale bg_par_atm_force_scale_val_3 =8.3333e+013 scale variable in user-config. biogem_force_flux_atm_pCO2_sig.dat (in mol) forcing file in cgenie.muffin/genie_forcings/ Then the true flux is 1× 8.33E13 mol/yr = 10E15 g C/yr = 1 Pg C/yr. -START-OF-DATA- 0.0 1.0 1.0 1.0 1.0 0.0 999999999.0 0.0 -END-OF-DATA- This can be plot as y~x. ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:8:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Historical emission forcing Define the forcing as worjh2.historical2010 in user-config and comment the scale variable, because this historical emission forcing directly follows the observed change in atmospheric concentration with time. set bg_par_misc_t_start=1765.0 which is the year to start transient (it’s often defined in pre-industrial age like 1700s). You can define as following to decide which year’s data should be saved (the profile is in biogem/data/input). bg_par_infile_slice_name='save_timeslice_historicalfuture.dat' bg_par_infile_sig_name='save_timeseries_historicalfuture.dat' Then run for 245 years and we come to year 2010. Any future modelling then can use this as new spin-up. There’re also some IPCC/SRES scenarios can be used, such as worjh2.FeMahowald2006.FpCO2_Fp13CO2_A2_02180PgC which provide IPCC ‘A2’ scenario. Ocean biogeomchemical cycle ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:9:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"nutrient’s control on biological productivity Basic-config: cgenie.eb_go_gs_ac_bg.worjh2.BASES (add more traces than last chapter) Parameters to play: bg_par_bio_k0_PO4=1.9582242E-06 #maximum rate of conversion of dissolved PO4 into organic matter (mol kg-1 yr-1) bg_par_bio_remin_POC_eL1=550.5195 #the depth-scale where POM is remineralizated bg_par_bio_remin_POC_frac2=6.4591110E-02 #the fraction of POM to export bg_par_bio_red_POC_CaCO3=0.044372 #CaCO3/POC ratio ea_36=y #climate-CO2 feedback bg_par_data_save_level=5 #data to save, check the instruction bg_par_bio_c0_PO4=2.1989611E-07 #[PO4] M-M half-sat value (mol kg-1) bg_par_bio_red_POP_POC=106.0 #redfield ratio bg_par_bio_red_DOMfrac=0.66 #how many organic matter produced is partitioned into dissolved (DOM) bg_par_bio_remin_DOMlifetime=0.5 #DOM mean lifetime (yr) in the ocean ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:10:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Iron and Phosphate fertilisation This determines the total flux of Fe and P. ## --- GEO: Fe --- bg_par_forcing_name=\"worjh2.FeMahowald2006.FpCO2_Fp13CO2_A2_02180PgC_FFe\" bg_par_ocn_force_scale_val_9=1.0e+09 ## --- GEO: PO4 --- bg_par_forcing_name=\"worjh2.FeMahowald2006.FpCO2_Fp13CO2_A2_02180PgC_FPO4\" bg_par_ocn_force_scale_val_8=2.0e+12 ## --- GEO: ALK --- bg_par_forcing_name=\"worjh2.FeMahowald2006.FpCO2_Fp13CO2_A2_02180PgC_FALK\" bg_par_ocn_force_scale_val_12=5.0e+13 ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:11:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"What to view Maybe pCO2 is a good option. EcoGEnIE Description: ECOGEM has poorer performance than BIOGEM in biogeochemistry (also because BIOGEM has been calibrated), but BIOGEM is unrealistic because it transform nutrient to POM/DOM instantly without passing from plankton biomass. Basic-config: muffin.CBE.worlg4.BASESFeTDTL ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:12:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Customization In user-config, we can define plankton file (another text file) by variable eg_par_ecogem_plankton_file. The data is in genie-ecogem/data/input/*.eco which has form like: -START-OF-DATA- Phytoplankton 0.60 1 Phytoplankton 6.0 1 Phytoplankton 60.0 1 Zooplankton 6.0 1 Zooplankton 60.0 1 Zooplankton 600.0 1 -END-OF-DATA- Columns mean functional type (including Diatom, Coccolithophore etc), diameter. The number 1 means nothing. Nutrient limitation: Turn on Fe limitation: set eg_useFe=.true. and eg_fquota=.true.. Then define eg_qminFe_a and eg_qmaxFe_a as the range of Fe. And bg_par_det_Fe_sol_exp determines the solubility of atmospheric iron inputs in seawater. ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:13:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Science"],"content":"Result to view Nutrient limitation: eco2D_xGamma_Fe_001 and co2D_xGamma_P_001 in netCDF file. The value is from 0 to 1, higher value means less limitation. Size metric: eco2D_Size_Mean/Stdev Size distribution: eco2D_Size_Frac_pico/nano/microphytoplankton. pico → ≤ 2 μ m nano → 2~20 micro → ≥ 20 um C:P biomass ratio Distribution pattern in different size class ","date":"2020-12-25","objectID":"/2020-12-25-cgenie-simplest-summary/:14:0","tags":["cGENIE"],"title":"cGEnIE Simplest Summary","uri":"/2020-12-25-cgenie-simplest-summary/"},{"categories":["Programming"],"content":"What’s LSP LSP is abbreviation of language server protocol, an idea proposed by Microsoft. According to its website, the idea behind the LSP is to standardize the protocol for how such servers and development tools communicate. In short words, LSP expect to standardize common features (i.e. auto-completion, go-to-definition, show-documentation, etc.) among different editors/IDEs. I knew this last night when I was finding some FORTRAN support on emacs; and was surprised by this great idea before I tried it (it was around 1 AM). Emacs implementation There’re two packages doint this, LSP-mode and eglot-mode. I tried the former firstly, surpring by its great functions and many integration, but soon found some bugs which I can’t solve (e.g. the deprecated function lsp-define-stdio-client error). Naturally I found eglot which is smaller and more suitable for me. I’ll show python and fortran suppport as following. Python and fortran support (use-package eglot :config (add-to-list 'eglot-server-programs '((c++-mode c-mode) \"clangd\")) (add-to-list 'eglot-server-programs '(f90-mode . (\"fortls\"))) (add-hook 'python-mode-hook 'eglot-ensure) (add-hook 'c-mode-hook 'eglot-ensure) ) The server for python (pyls) and fortran (fortls) respectively need to be pre-installed. Both can be downloaded through pip. Clangd which is used for C and Cpp need to be compiled and installed instead. ","date":"2020-12-17","objectID":"/2020-12-17-lsp-mode/:0:0","tags":["Emacs; LSP"],"title":"LSP Mode","uri":"/2020-12-17-lsp-mode/"},{"categories":["Programming"],"content":"Emacs in Windows Following are multiple ways to run emacs in Windows. Emacs for windows WSYS2 (pacman -S Emacs) WSL/WSL2 emacs The first one should be the easiest way to install and run, yet it’s not so good to use. For example, I’m struggling with environmental variable. Firstly, There’re C:\\Users\\usrname\\app\\roaming and C:\\Users\\usrname confusing me of which one should be $HOME, especially when I use university-distributed pc and don’t have root permission to modify System variable. Secondly and similarly, when I use python, which python should I use, anaconda? The .exe file from python website? or the automatic answer, python in the windows store? The third one, I can’t use tramp-mode easily as in other OS. The last one, when I open emacs by pressing their shortcut, the default path through entring C-x C-f is not ~ that I want. Certainly you can define an exact path in the property, but emmm, it’s just so hard to use. WSYS2 is good to use as well, they provide unix-like environment and you can use pacman like in arch-linux. But I met an issue that I can’t download package after downloading python-pip, which means I can’t use python like in unix (I don’t know why either). Finally, we have the last option: downloading Ubuntu/Debian/CentOS in windows store and use X-server (e.g. MobaXterm, VcXsrv, X410, Xming) to visualise GUI instead of runing in WSL terminal. #add following code to your shell configuration file #WSL1 echo export DISPLAY=0:0 #WSL2 export DISPLAY=\"$(/sbin/ip route | awk '/default/ { print $3 }'):0 However, honestly I didn’t find it significantly faster than in WSYS2 (it’s pretty faster in WSL2 than WSL1), but I can use it very conveniently. Of course, “relatively complex” things always exist. For instance I need to install emacs 27.1 by compling source codes, because in the apt the dafult emacs version is 26.1. Also, if you use high DPI screen as me, you need to open compatibility and change DPI setting in shortcut property. Lastly, the CJK font and input method for emacs seems to be another brain-blowing thing… There’re also other alternative ways like Docker, a pure virtual machine (VMware) but I haven’t try them. ","date":"2020-12-12","objectID":"/2020-12-12-run-emacs-in-wsl/:0:0","tags":["Emacs; WSL"],"title":"Run Emacs in WSL2","uri":"/2020-12-12-run-emacs-in-wsl/"},{"categories":["Programming"],"content":"Core packages There’re several packages to achieve functions as IDE or visual studio code: elpy, jedi and anaconda-mode are the most used. Jedi seems to be ","date":"2020-12-12","objectID":"/2020-12-12-use-emacs-as-python-ide/:0:0","tags":["Emacs; python"],"title":"Use Emacs as a Python IDE","uri":"/2020-12-12-use-emacs-as-python-ide/"},{"categories":["Programming"],"content":"Prerequisites Elpy requires some prerequisites, like Jedi, Rope and some others which you need to download through pip, the python package manager. You can check the list through \"M-x elpy-config\" and install them before using elpy properly. In this process, I’ve encountered a problem that even after downloading these packages I still cannot use elpy. This is because the installed packages are in ~/local/bin and I didn’t add it in PATH. the solution is either add it or use sudo -H pip install. ","date":"2020-12-12","objectID":"/2020-12-12-use-emacs-as-python-ide/:1:0","tags":["Emacs; python"],"title":"Use Emacs as a Python IDE","uri":"/2020-12-12-use-emacs-as-python-ide/"},{"categories":["Programming"],"content":"Activiate Virtualenv Elpy recommend to use virtualenv and you need to download Virtualenv through pip as well. Makedir to generate a new folder and use virtualenv command to create a virtualenv folder. Finally, use M-x pyvenv-activate to activate it. ","date":"2020-12-12","objectID":"/2020-12-12-use-emacs-as-python-ide/:2:0","tags":["Emacs; python"],"title":"Use Emacs as a Python IDE","uri":"/2020-12-12-use-emacs-as-python-ide/"},{"categories":["Programming"],"content":"Company-quickhelp Basically you can successfully use elpy after steps above. C-c C-c to send region to python interactive interpreter, C-c C-d to show documentation, M-. to go to definition. If you stop cursor at some point for a moment, the minibuffer will automatically show simple documentation. But we can use company-quickhelp to move it to a box. See the following snapshoot. My configuration and snapshoot (use-package elpy :init (elpy-enable) :config (setq python-shell-interpreter \"ipython\" ;require pip install ipython python-shell-interpreter-args \"-i --simple-prompt\") (add-hook 'python-mode-hook 'eldoc-mode) (setq elpy-rpc-python-command \"python3\") (setq elpy-shell-echo-output nil) (setq python-shell-completion-native-enable nil) (setq elpy-rpc-backend \"jedi\") (setq python-indent-offset 4 python-indent 4) ) (use-package company-quickhelp :config (company-quickhelp-mode 1) (eval-after-load 'company '(define-key company-active-map (kbd \"C-c h\") #'company-quickhelp-manual-begin))) ","date":"2020-12-12","objectID":"/2020-12-12-use-emacs-as-python-ide/:3:0","tags":["Emacs; python"],"title":"Use Emacs as a Python IDE","uri":"/2020-12-12-use-emacs-as-python-ide/"},{"categories":["Programming"],"content":"Aim of this blog To record the process of embedding Chinese font(or other CJK fonts) in R-created pdf files. ","date":"2020-03-31","objectID":"/2020-03-31-embedding-chinese-fonts-in-r/:1:0","tags":["R; Chinese fonts"],"title":"Embedding Chinese Fonts in R","uri":"/2020-03-31-embedding-chinese-fonts-in-r/"},{"categories":["Programming"],"content":"Used packages showtext(primary) extrafont ","date":"2020-03-31","objectID":"/2020-03-31-embedding-chinese-fonts-in-r/:2:0","tags":["R; Chinese fonts"],"title":"Embedding Chinese Fonts in R","uri":"/2020-03-31-embedding-chinese-fonts-in-r/"},{"categories":["Programming"],"content":"Example If you wanna simply show chinese text in plot, showtext package is enought, ‘cause it includes a open source font “wqy-microhei” Here is an example. library(showtext) library(ggplot2) showtext_auto() #plot example set.seed(123) x \u003c- rnorm(10) y \u003c- rnorm(10) df \u003c- data.frame(x=x,y=y) p \u003c- ggplot(data=df,aes(x,y))+geom_point()+geom_smooth()+ theme_bw(base_family = \"wqy-microhei\") p + xlab(\"中文\")+ylab(\"字体\") ","date":"2020-03-31","objectID":"/2020-03-31-embedding-chinese-fonts-in-r/:3:0","tags":["R; Chinese fonts"],"title":"Embedding Chinese Fonts in R","uri":"/2020-03-31-embedding-chinese-fonts-in-r/"},{"categories":["Programming"],"content":"Another Example If you gonna use other fonts in R, such as Songti(“宋体”) which is used in many Chinese academic article, you need to firstly download (or copy them from your OS) and import them, and use them as the previous example. # import fonts from Windows library(extrafont) library(showtext) library(ggplot2) #Strategy1 COPY FONTS FROM SYSTEM #Note: You have to run font_import() again when you have one new font font_import() loadfonts(device=\"pdf\") fonts() #show all fonts #Straetegy2 ADD ONE FONT font_add(\"Songti\",\"~/Downloads/SourceHanSanSerif.otf\") #Strategy3 DOWNLOAD FONTS font_add_google(\"Lobster\", \"lobster\") set.seed(123) x \u003c- rnorm(10) y \u003c- rnorm(10) df \u003c- data.frame(x=x,y=y) p \u003c- ggplot(data=df,aes(x,y))+geom_point()+geom_smooth()+ theme_bw(base_family = \"Songti\") p + xlab(\"中文\")+ylab(\"字体\") ","date":"2020-03-31","objectID":"/2020-03-31-embedding-chinese-fonts-in-r/:4:0","tags":["R; Chinese fonts"],"title":"Embedding Chinese Fonts in R","uri":"/2020-03-31-embedding-chinese-fonts-in-r/"},{"categories":null,"content":"Biography 🌊 I am now a CSC-funded PhD student at School of Earth Sciences, University of Bristol studying planktic foraminifera, a group of marine zooplankton exsiting in the Earth since the mid-Jurassic (160 Ma). Despite focusing on foram, My scientific interests are understanding the fundamental ecological mechanisms. For example, how global changes influence marine plankton ecology/evolution processes and corresponding functions? My main tool is an Earth system model, cGEnIE. ","date":"2020-02-02","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"CV Click me ","date":"2020-02-02","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Publications Goolge Scholar ","date":"2020-02-02","objectID":"/about/:3:0","tags":null,"title":"About","uri":"/about/"},{"categories":["Science"],"content":"分类地位 鲑形目(Salmoniformes) -鲑科(Salmonidae) -鲑属(Salmo) ","date":"2019-07-03","objectID":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/:1:0","tags":["salmon"],"title":"如何分辨三文鱼、鲑鱼、大马哈鱼","uri":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/"},{"categories":["Science"],"content":"市场上常见的商品种 大西洋鲑(Salmo salar) 银鲑(Oncorhynchus kisutch) 虹鳟(Oncorhynchus mykiss) 大鳞大马哈鱼/帝王鲑(Oncorhynchus tshawytscha) 大马哈鱼/狗鲑(Oncorhynchus keta) ","date":"2019-07-03","objectID":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/:2:0","tags":["salmon"],"title":"如何分辨三文鱼、鲑鱼、大马哈鱼","uri":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/"},{"categories":["Science"],"content":"被混淆的概念 三文鱼：音译自salmon，英文中泛指鲑鱼。但在中文成为一个商品名，指代大西洋鲑(英文俗名Atlantic salmon，学名Salmo salar, 也叫安大略鲑)。 鳟：泛指鲑鱼中的一些物种，对应英文trout，例如虹鳟。 大马哈鱼：原本应该指代鲑科大马哈鱼属，真正的大马哈鱼的特性是在产卵后会死亡。但在中文俗称中，泛指太平洋鲑。 ","date":"2019-07-03","objectID":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/:3:0","tags":["salmon"],"title":"如何分辨三文鱼、鲑鱼、大马哈鱼","uri":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/"},{"categories":["Science"],"content":"三文鱼和虹鳟的区别 三文鱼是溯河洄游性鱼类，虹鳟是淡水鱼类(淡水鱼类不适合生食)。 ","date":"2019-07-03","objectID":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/:4:0","tags":["salmon"],"title":"如何分辨三文鱼、鲑鱼、大马哈鱼","uri":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/"},{"categories":["Science"],"content":"如何分辨市场上的三文鱼和虹鳟 三文鱼嘴型钩状 切片肉脂肪更多，色泽没有虹鳟鲜艳 三文鱼适合厚切 ","date":"2019-07-03","objectID":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/:5:0","tags":["salmon"],"title":"如何分辨三文鱼、鲑鱼、大马哈鱼","uri":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/"},{"categories":["Science"],"content":"参考 https://www.guokr.com/article/439738/?page=2 https://www.zhihu.com/question/26107303/answer/475905079 ","date":"2019-07-03","objectID":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/:6:0","tags":["salmon"],"title":"如何分辨三文鱼、鲑鱼、大马哈鱼","uri":"/2019-07-03-%E5%A6%82%E4%BD%95%E5%88%86%E8%BE%A8%E4%B8%89%E6%96%87%E9%B1%BC%E9%B2%91%E9%B1%BC%E5%A4%A7%E9%A9%AC%E5%93%88%E9%B1%BC/"},{"categories":["Science"],"content":"Note: I wouldn't force myself to use LaTeX like this article was to say. I would be practical to choose my tools, because they are just tools. 什么是LaTeX LaTeX（/ˈleɪ.tɛk/）是Leslie Lamport基于TeX开发的排版系统，而TeX则是由Prof. Donald Knuth发明的排版软件。他发明TeX排版软件最初是用作解决数学公式排版的问题，但在不断推广下，现在已经成为数学、物理、计算机领域几乎最重要的排版、编辑系统。 TeX最大的不同是，它相当于一门宏语言或标记语言。 LaTeX是TeX家族中一种编译引擎。除了LaTeX，还有XeLaTeX、pdfTeX、LuaTeX等等。 Why LaTeX 为什么要选择LaTeX而不是word？这是许多生命科学领域的科研工作者第一个要问的。事实上，我们大多数人是没有接触过除了word以外的写作排版软件，但在经历过word格式的折磨(如删除页眉的横线、版本控制)后，才发现别的选择有多好。 生科类的工作者对于写作软件一般关注几个问题：文献管理、投稿格式(包括文献格式)、部分公式，而latex基本就是为了格式和内容分离而诞生的。 特性 LaTeX MS Word 收费 免费 ￥400/y 平台支持 Linux/MacOS/Windows 基本只有windows才能用 数学公式 非常好 只能应付简单的公式 学术出版商支持 IEEE/Spring/Weily/Elseiver/Oxford等几乎所有学术出版商 同左 安装LaTeX 完整的TeX需要最基本的TeX引擎、格式支持、各种辅助宏包、一些转换程序、GUI、编辑器、文档查看器等等。这些组成起来就是TeX发行版。就像CentOS、ArchLinux这些和Linux的关系一样。 三大操作系统下支持的发行版会略有不同。一般而言，Windows、Linux下可选择使用TeX Live，MacOS 可以选择使用Mactex. 这些发行版安装文件会比较大（几个G），可以选择在清华大学镜像中下载。 不过也有更好的选择，也是越来越流行的选择，就是使用Overleaf在线编辑，免安装，免配置。具体如下编辑器介绍。 选择编辑器 因为.tex源文件是纯文本，所以一款tex编辑器很影响写作体验。好的会让你感觉像某个巧克力品牌一样丝滑流畅，越写越上瘾；差的则会分散你的注意力，造成负作用。私以为，一个好的编辑器应该具有以下几个特性： 高亮文本 实时预览 自动补全 好看的主题配色和字体 这里推荐overleaf (online) and Visual Studio Code (Editor). 基本的命令介绍 安装好LaTeX看起来像在写代码的原因就是因为它丰富的命令与宏包。这里只做简单介绍，更多还是要靠自己多用多摸索。 一个最基本简单的latex文档框架会有以下命令: \\documentclass[UTF8]{article} %文档类型，学术写作基本是article, []内是参数选项表示用utf8编码 \\begin{document} %开始文档 hello world %正文区 \\end{document} %结束文档 当然还会有其他信息 \\documentclass{article} \\title{my first tex file} \\author{name} %作者名称 \\date{\\today} %这里就可以看出latex的黑魔法了，直接用\\today表示日期 \\begin{document} \\maketitle %这里会根据上述的title,author,date信息自动生成一个标题 \\section{section1} %第一节 \\section{section2} %第二节 \\subsection{subsection1} %第二节中的第一部分，更多层级标题可以通过\\subsubsubsection这样添加 \\end{document} ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:0:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Science"],"content":"添加数学公式 $....$ %所有行内公式都可以在两个$之间插入 \\begin{equation} %行间公式，可以使用equation环境 d = \\frac{a}{b} + \\sqrt{c} %使用\\frac{}{}表示分式，使用\\sqrt{}表示根式 \\end{equation} 更多的数学公式符号可以参考lshort一份很短的latex入门文档 ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:1:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Science"],"content":"插入表格 tabular 环境提供了最简单的表格功能。它用 \\hline 命令表示横线，在列格式中用 | 表示竖线；用 \u0026 来分列，用 \\\\ 来换行；每列可以采用居左、居中、居右等横向对齐方式，分别用 l、c、r 来表示。 \\begin{tabular}{|l|c|r|} \\hline species\u0026 biomass\u0026 abudance\\\\ \\hline a\u0026 100\u0026 10\\\\ \\hline b\u0026 10\u0026 10\\\\ \\hline \\end{tabular} ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:2:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Science"],"content":"插入图片 \\documentclass{article} \\usepackage{graphicx} \\begin{document} \\includegraphics{fig1.eps} %这里a.eps在同目录下。这里推荐eps是因为它是矢量图，可以保证图像质量 \\end{document} %对于想控制图像大小的可以添加参数 %\\includegraphics[width=5cm]{Fig1} ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:3:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Science"],"content":"中文排版（其实没什么必要，国内期刊应该基本不接收这种格式，他们也看不懂） \\documentclass[UTF8]{ctexart} %其他相同，编译使用xelatex即可 学术写作你最关心的那些点 /待定 ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:4:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Science"],"content":"多位作者 /待定 ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:5:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Science"],"content":"如何插入文献 Word里有Endnote那样的软件配合插入文献。latex当然也有，那就是BibTeX。BibTex生效过程有4大步骤，如下： latex编译.tex文件，生成.aux文件（auxiliary之意）, 这个文件将告诉bibtex有哪些引用信息 BibTeX编译.bib文件，根据.aux文件检测.bib中的相关文献 LaTeX重编译.tex文件，把参考文献编入文档 LaTeX再次编译.tex文件，防止交叉引用出错 当然使用的时候不需要知道这么多，只要知道三个命令即可 \\cite{ref} %在文中引用文献 \\bibliographystyle{stylefile} %同目录下的文献格式文件，由期刊提供 \\bibliography{sample} %你的文献库 如下图所示，我在Google scholar export我的文章为bib格式并放在同目录下，然后在.tex中的#74行\\cite{xxx}引用了它，右边就自动编译出了reference。#85-86行是模板中已经预设好的命令，只需要在\\bibliography{}中填上test表示test.bib为文献库既可。 事实上文献库不可能只有一个文献，所有可以用endnote这样的文献管理软件导出bib文件(应该没有不能导出的软件，否则它就是失败的)。要注意的是，这样的bib文件在投稿时一定要一起上传，否则期刊是不知道你引用了什么文献的。 不过说到文献管理软件的话，这里更推荐Zotero搭配LaTeX，为什么呢，因为它也是开源免费的。 ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:6:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Science"],"content":"投稿格式/模板使用 其实如上面所言，投稿时一般的期刊都会提供模板(具体见author guidlines)，例如Journal of Animal Ecology，里面会有所有要求的格式（如上编辑器截图）。作者只需要按照指示，在上面填充自己的内容即可。 但是也有一些不用模板的，例如Ecology Letters（如下）。不过这种反而是种优势？至少你不用改格式了，peer-review时提供pdf，终稿时提供source file、图片还有bst文件就可以了。 Ecology Letters does not have a standard LaTex style file. Manuscripts submitted using LaTeX should be accompanied by a PDF version of the paper. Upon final acceptance for publication, authors will be requested to send their LaTeX source files accompanied by all figures in EPS or TIFF format and also any non-standard LaTeX style files used in the manuscript preparation. ","date":"2019-07-03","objectID":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/:7:0","tags":["LaTeX"],"title":"LaTeX学术写作与排版简介","uri":"/2019-07-03-%E7%AE%80%E4%BB%8B%E5%A6%82%E4%BD%95%E7%94%A8latex%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E4%B8%8E%E6%8E%92%E7%89%88/"},{"categories":["Programming"],"content":"C语言预处理 C的编译过程分为三步。以hello.c为例子，从源代码.c到可执行文件（如windows下的.exe）的过程是： 过程 名称 GCC代码 作用 hello.c -\u003e hello.i 预处理 gcc -E hello.c 预处理头文件及宏 hello.i -\u003e hello.s 编译 gcc -S hello.i 转为汇编代码 hello.s -\u003e hello.o 汇编处理 gcc -C hello.s 转为机器码，生成目标文件 hello.o -\u003e hello 链接 gcc hello.o 生成可执行文件 C语言预处理是编译过程的第一步，将源文件.c处理为.i文件。其中预处理就包括对#define指令的翻译。 #define语句不是专属于C语言的语句，它是一个宏。而宏是完全的文本替换。 所以/#define不用分号结束语句，换行时要使用'/'。 #define宏因此也可以用作定义函数。所有参数和整体都要带括号，因为替换中可能会出现意外的运算顺序错误。 #运算符的作用是将变量转化为字符串。如#x == \"x\"。 ##运算符就是一个黏合剂，如x ## 2 == x2 预处理也会处理#include头文件，也就是插入一些.head文件。在#include .h的时候常常可能造成重复声明，所以可以通过#ifndef, #define, #endif 这3个语句来进行检验。 ","date":"2018-12-06","objectID":"/2018-12-06-c%E8%AF%AD%E8%A8%80%E9%A2%84%E5%A4%84%E7%90%86/:0:0","tags":["C"],"title":"C语言预处理","uri":"/2018-12-06-c%E8%AF%AD%E8%A8%80%E9%A2%84%E5%A4%84%E7%90%86/"},{"categories":["Programming"],"content":"1. 字符串输入 C语言本质上也是一种面向用户的程序，所以必须把尽可能多的细节告诉它。 例如，在处理字符串输入的时候，我们必须先告诉它需要多少空间。所以，下面这种情况就是错误的。 char *name; scanf(\"%s\", name); ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:1:0","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"1.1 gets()函数 gets()的用法非常简单 char words[SIZE]; get(words); 像上面的两段式就能实现读取输入：先指定大小，再获取输入。gets()会读取整行然后丢弃\\n换行符，并且在字符串末尾添加\\0空字符。 但是gets()已经被废除， 因为它有致命的缺陷，就是他无法检查数组是否装得下输入行。如果输入字符串过长，那么会导致缓冲区溢出，造成安全问题。 ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:1:1","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"1.2 fgets()函数 fgets()函数被用来替代gets，但是它的参数有3个。 fgets( string, SIZE, stdin) 3个参数分别为字符串变量，字符串容量大小，标准输入的意思。 与之对应的，是fputs函数 fputs(string, stdout) 参数和上面类似，stdout代表标准输出。 fgets与gets的区别有主要几点： fgets限制读入字符数，读入size - 1的字符（最后一个为\\0），或者到遇到第一个换行符为止 fgets会存储换行符，gets会丢弃换行符 同样地，puts函数也会在末尾添加一个换行符（换行符真的是C语言最繁琐的地方之一）。 当你想用fgets()舍弃换行符的时候，可以采取 while (words[i] != '\\n') i++; words[i] = '\\0'; //用空字符替代换行符 //或者丢弃换行符后面的字符 /* while (getchar() != '\\n') continue; */ ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:1:2","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"2. 字符串输出 ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:2:0","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"2.1 puts()函数 puts函数很常用，但是要知道它的几个特性 puts会在末尾添加换行符 puts必须要看到 \\0才知道停止 ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:2:1","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"2.2 fputs()函数 与puts不同，fputs不会在输出末尾添加换行符。 ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:2:2","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"2.3 printf()函数 无需多言，可以格式化不同的数据类型，也不会自作主张添加换行符。 ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:2:3","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"3. 总结 换行处理 输入 输出 丢弃 gets() fputs, printf() 保留 fgets() puts ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:3:0","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"4. 参考资料 [1] C Primer Plus ","date":"2018-12-03","objectID":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/:4:0","tags":["C"],"title":"C语言字符串IO","uri":"/2018-12-03-c%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2io/"},{"categories":["Programming"],"content":"数组名是常量，指针是变量 C语言中，数组和指针经常被混淆。如下一个例子: char ar[] = \"ABC\"; const char *pt[] = \"ABC\"; 他们的共同点在于，都可以进行基本的数组表示。 for (i = 0; i \u003c 3; i++) putchar(ar[i]); //or putchar(pt[i]); 或者进行指针加法操作： for (i = 0; i \u003c 3; i++) putchar(*(ar+1)); //or putchar(*(pt[i])); 其实数组名的本质在于，他是数组首元素的地址常量，也就是一串十六进制的数值。所以它可以通过指针加法来表示下N个元素。 而指针的本质在于，它是某个变量（这里是一个字符串）的地址，是一个变量，所以它不但可以进行上述操作，还可以进行递增操作，例如pt++，或者展开来pt = pt +１。数组不能这样操作是因为它是不可变的。你可以用ar + n来表示其他元素，但你不能用ar++这样的形式。 ","date":"2018-12-02","objectID":"/2018-12-02-c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84%E5%92%8C%E6%8C%87%E9%92%88/:1:0","tags":["C"],"title":"C语言数组和指针","uri":"/2018-12-02-c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84%E5%92%8C%E6%8C%87%E9%92%88/"},{"categories":["Programming"],"content":"初始化数组是cp, 初始化指针是mv 同样是上面的例子，ar和pt都指向“ABC”这个字符串。但是，事实上，用printf(%p)就可以试出来，pt指针是和\"ABC\"的地址是一样的，ar数组是和\"ABC\"的地址是不一样的。因为初始化数组是将静态存储区的字符串拷贝到数组中，而初始化指针只是把字符串的地址传递给指针。所以，初始化数组是进行创建副本，而初始化指针只是告诉你一个地址，没有进行字符串的移动。 可以看出来，指针是相对灵活的。但是，在某些时候也会造成错误。例如如果在表示字符串时，如果没有用const表示常量，就可能会字符串的地址造成修改，进而影响整个字符串代码。所以最好用const限定字符串常量。 ","date":"2018-12-02","objectID":"/2018-12-02-c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84%E5%92%8C%E6%8C%87%E9%92%88/:2:0","tags":["C"],"title":"C语言数组和指针","uri":"/2018-12-02-c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84%E5%92%8C%E6%8C%87%E9%92%88/"},{"categories":["Programming"],"content":"参考资料 [1] C Primer Plus第六版 ","date":"2018-12-02","objectID":"/2018-12-02-c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84%E5%92%8C%E6%8C%87%E9%92%88/:3:0","tags":["C"],"title":"C语言数组和指针","uri":"/2018-12-02-c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84%E5%92%8C%E6%8C%87%E9%92%88/"},{"categories":["Programming"],"content":"Git简介 Git由Linus开发以实现版本控制，（几乎）是现在最流行的版本控制系统。与分布式对应的是集中式管理（Centralized Version Control System），他们的区别是，集中式只有一个总服务器，N个客户端共用一套数据；而分布式是每个客户端都有一整套的镜像数据。Git官网给出了关于Git的详细文档（它支持多国语言），所以本文主要是做一个简单的介绍以及对我自己的复习。 另外，Git is free! ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:1:0","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"安装Git 要想学Git，第一步自然从安装开始。不过不同于一些依赖环境的软件，Git安装很简单，去官网找一下就行了。Linux系统（如Ubuntu）直接用sudo apt-get install git安装，Windows则下载对应的setup狂按下一步就OK了。 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:2:0","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"使用Git ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:3:0","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"基本命令 相信用Git的人都不会是小白，所以命令行是必须的。下面是一些基本的命令。 1. git config --global user.name/email =\u003e 配置你的信息 2. git init =\u003e 初始化一个仓库（repository） 3. git add =\u003e 添加到缓冲区 4. git commit (-m \"message\") =\u003e 提交 //分add+commit两步走的原因是commit可以提交多个文件 5. git status =\u003e 查看状态 6. git log =\u003e 查看log日志 7. git rm =\u003e 删除文件 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:3:1","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"版本回溯 版本管理，形象的就是一条时间线上的不同版本，本质上就是不同的文件。所以要想随意地穿梭于各个版本之间，就必须对每个版本产生一个独一无二的ID。在Git中，commit ID是一串十六进制数字，之所有这么做是避免每个client的ID的重复。此外，在git中有一个指向__当前__版本的HEAD指针，版本的切换其实就是用HEAD指向不同的版本。 说了这么多，其实版本的“倒带”命令很简单，git reset --hard ID即可，ID也可以用HEAD^来表示相对版本，每一个^就代表往回走一步。当^太多了怎么办？用HEAD~n来表示回溯n个版本。 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:3:2","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"版本前进 问题来了，回去了怎么回来？用git log找到commit ID，然后reset回来即可。 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:3:3","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"远程仓库 现在我们觉得在本地修修改改没有意思，现在还想把本地文件放在远程仓库托管。 那么第一个最基本的操作就是把本地和远程关联起来。输入命令git remote add origin your_url，这里origin就是远程仓库的名字，是git的默认叫法。而远程仓库可以用GitHub、gitlab、码云等网站注册。 第二步呢，就是把本地的文件传到远程仓库。命令是git push -u origin master，不过呢在这里还要进行验证，Git服务器通过SSH KEY来进行认证，没有SSH KEY怎么办？很简单，生成一个。在命令行里输入ssh-keygen -t rsa -C \"your_email@example.com即可，生成的密钥在.ssh目录中，分别id_rsa和id_rsa.pub两个文件，.pub的就是公钥，可以用来添加到GitHub中完成连接。 不过，即便是SSH关联了，在后面git push时也可能要你输入用户名和密码，这是因为你在clone时可能用的是https方式，这时候就要在项目文件夹里的.git/config里修改remote origin url为ssh://git@github.com/name/repos.git即可了。 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:3:4","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"分支管理 分支就是相当于一个平行空间，每一个分支的变化都不会影响其他的分支。在Git中，主分支称为master，用户可以通过创建额外的分支来进行开发，然后和主分支进行合并，完成修改，之后，再将分支删除掉。以下是常用命令: 0. git branch =\u003e 查看分支 //当加上\u003cbranch.name\u003e时就是创建分支 1. git checkout =\u003e 切换分支 2. git merge =\u003e 合并分支 3. git branch -d =\u003e 删除分支 4. git pull =\u003e 更新本地仓库 在合并中，很可能会出现矛盾，这会让git不知道听哪一个的。所以就要手动解决冲突，然后再进行合并。 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:4:0","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"分支的本质 要用好Git，就要理解好Git分支的原理。Git把我们的工作分成了几个区域: 0. 工作区(file) 1. 暂存区(stage/index) 2. 版本库(branch) 3. 远程仓库(remote) 每一次步骤分别使用add命令将文件添加到暂存区，用commit命令提交到分支中。每次commit之后，就会产生一个提交对象(commit object), 它包含着提交文件的基本信息还有指向tree对象的指针，tree对象记录着文件的结构还有blob对象(就是文件快照)的索引。所以每次提交会产生以下的对象: commit object \u003e tree object \u003e blobs, 每一次提交像一个神经元一样，连成一整个timeline: --O--O--O---O 而分支，其实就是指向这些神经元的指针，而HEAD就是指向当前状态(分支)的指针（如下）。 git_branch 所以，当你创建一个新的分支的时候，其实只是换了一个指针，其他的文件都没有变化（有点像C语言是吧）。这使得Git的速度非常快，也是Git超出其他版本控制软件的重要原因或理念。另外一提，Git也是不依赖于网络的，它基于本地资源，可以大大减少对网络的依赖并且提升自身的速度。 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:5:0","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"标签管理 每个版本都会有对应的版本号，其实就是和commit ID一样的东西。但是我们当然不能用那一串十六进制的数值来表示，所以Git支持用户自己给版本打标签，命令同样很简洁明了，如git tag v1.2即可，标签是默认在最近的提交上的。 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:6:0","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"参考资料 廖雪峰 Git官网 Git简明教程 ","date":"2018-11-25","objectID":"/2018-11-25-git-study/:7:0","tags":["Git"],"title":"Git Study","uri":"/2018-11-25-git-study/"},{"categories":["Programming"],"content":"Writing Markdown under emacs can use markdown-mode to perform convenient operations such as syntax highlighting and preview. Specific commands can be obtained through Emacs wiki or documentation. However, it is worth mentioning that preview should set the markdown command of emacs to a specific variable, for example, “/usr/bin/pandoc” is to connect pandoc and md files, and then Cc Cc P to preview, the preview is on the web So it should be converted to html through pandoc. Update: now I use Emacs org-mode to export markdown file, and use grip-mode to preview it. ","date":"2018-11-25","objectID":"/2018-11-25-use-emacs-to-write-markdown/:0:0","tags":["Emacs; Markdown"],"title":"Use Emacs to Write Markdown","uri":"/2018-11-25-use-emacs-to-write-markdown/"},{"categories":["Programming"],"content":"C语言下的转换说明修饰符 scanf()和getchar()函数的不同在于,getchar()函数和scanf(%c)接受包括转行符在内的所有字符，而使用其他转换修饰符的scanf()则可以通过转换说明限制输入的字符类型。例如，在声明中，char a;声明a变量是一个字符，但是我偏偏打进去一个数字96，结果编译器没有报错。为什么呢，因为getchar读取了数字96并且把他存成了一个字符串变量。而scanf()则可以通过%d等来告诉计算机，只要真的数字而不是string。所以，当你用scanf输入错误的数据类型时，会得到 warning: format ‘%d’ expects argument of type ‘int *’, but argument 2 has type ‘char *’ [-Wformat=] scanf(\"%d\", \u0026a); ~^ ~~ %hhd 意思就是数据类型不匹配。同样地，如果一开始声明变量就是字符串外的其他类型，那么也一样会报错。 所以一个输入流程应该是 input \u003e if char \u003e %convertion(if %c or getchar: pass) \u003e variable 在获取用户输入的时候，就要尤其注意，要添加一段while (getchar() != '\\n') continue;来跳开换行符。 printf()函数也可以通过转换说明修饰符（例如%d, %c ）来对输出进行转换。例如下面的代码： #include \u003cstdio.h\u003e int main(void) { int a; scanf(\"%d\", \u0026a); printf(\"%c\\n\", a); return 0; } 我输入一个int整数，结果可以转化为相应的字符。因为在计算机中，无论是整数还是字符，都只是二进制的01序列而已。所以，转换说明也相当于一个翻译的作用，例如将十进制输出为十六进制（%x）。 ","date":"2018-11-23","objectID":"/2018-11-23-c%E8%AF%AD%E8%A8%80%E4%B8%8B%E7%9A%84%E8%BD%AC%E6%8D%A2%E8%AF%B4%E6%98%8E/:0:0","tags":["C"],"title":"C语言下的转换说明","uri":"/2018-11-23-c%E8%AF%AD%E8%A8%80%E4%B8%8B%E7%9A%84%E8%BD%AC%E6%8D%A2%E8%AF%B4%E6%98%8E/"}]